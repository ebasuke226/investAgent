{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f82ad093-eea7-4fa9-ac9d-8089af41468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import google.generativeai as genai\n",
    "\n",
    "# ✅ Gemini API の設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, use_summary=True):\n",
    "    \"\"\"PDFからマーケット情報を抽出し、クリーニング後にGeminiで要約\"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    raw_text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "    \n",
    "    # ✅ クリーニング処理\n",
    "    clean_text = clean_pdf_text(raw_text)\n",
    "    \n",
    "    if use_summary:\n",
    "        summary = summarize_with_gemini(clean_text)\n",
    "        return summary  # 要約のみ返す場合\n",
    "        # return clean_text + \"\\n\\n--- 要約 ---\\n\" + summary  # 要約を元のテキストと併せて返す場合\n",
    "\n",
    "    return clean_text  # 要約を使わない場合はクリーンテキストのみ\n",
    "\n",
    "def clean_pdf_text(text):\n",
    "    \"\"\"抽出したテキストを整形して不要な部分を削除\"\"\"\n",
    "\n",
    "    # ✅ ページ番号やURLの削除\n",
    "    text = re.sub(r\"\\s*[-_]+\\s*\\d+/\\d+\\s*[-_]+\", \"\", text)  # \"1/3\", \"2/3\" などのページ表記\n",
    "    text = re.sub(r\"https?://\\S+\", \"\", text)  # URLを削除\n",
    "\n",
    "    # ✅ 免責事項・注意書きを削除\n",
    "    exclusion_patterns = [\n",
    "        r\"本資料に関してご留意頂きたい事項.*$\",\n",
    "        r\"出所）.*?$\",\n",
    "        r\"本資料は.*?作成されたものです。\",\n",
    "        r\"本資料は、作成時点 で.*$\",\n",
    "        r\"本資料の内容は.*?変更されることがあります。\",\n",
    "        r\"本資料は.*?保証するものではありません。\",\n",
    "        r\"本資料に示す意見等は.*?限りません。\",\n",
    "        r\"本資料中で使用している指数について.*$\",\n",
    "    ]\n",
    "    for pattern in exclusion_patterns:\n",
    "        text = re.sub(pattern, \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # ✅ 連続する空白・改行の削除\n",
    "    text = re.sub(r\"\\n\\s*\\n\", \"\\n\", text)  # 空行を削除\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)  # 連続する空白を1つに\n",
    "    text = text.strip()\n",
    "\n",
    "    # ✅ 数値だけの行・不要なヘッダーの削除\n",
    "    clean_lines = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        if re.match(r\"^\\s*[\\d.,/%]+\\s*$\", line):  \n",
    "            continue\n",
    "        if re.search(r\"^\\s*(単位|注）|.*?は.*?です。)\", line):  \n",
    "            continue\n",
    "        clean_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(clean_lines).strip()\n",
    "\n",
    "def summarize_with_gemini(text):\n",
    "    \"\"\"Gemini に問い合わせてテキストの要約を取得\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    以下のテキストから観点に沿った情報に絞って詳細を教えて。\n",
    "    \n",
    "    {text}\n",
    "    \n",
    "    観点：[1. 主要金融市場の動き,2. 主要国株式の動き,3. マーケットの動き,4.注目点]\n",
    "    なお、免責事項などの記載は無駄な文章なので除外して。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        if hasattr(response, \"text\") and response.text:\n",
    "            return response.text.strip().replace(\"\\n\",\"\").replace(\"*\",\"\")\n",
    "        else:\n",
    "            print(f\"⚠️ 要約取得失敗: {response}\")\n",
    "            return \"要約取得に失敗しました。\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gemini 要約エラー: {str(e)}\")\n",
    "        return \"要約取得中にエラーが発生しました。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f67f77c0-8df9-4a3d-ad27-c5ecfa0b2164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 主要金融市場の動き 主要国株式:  日経平均株価は38,678.04円（前日比-486.57円）、TOPIXは2,734.60（前日比-32.65）。米国株はNYダウが44,176.65ドル（前日比-450.94ドル）、S&P500が6,117.52（前日比-26.63）、ナスダック総合指数が19,962.36（前日比-93.89）と下落。その他、ドイツDAX、英国FTSE100、豪州S&P/ASX200、中国上海総合指数、香港ハンセン指数、インドS&P BSE SENSEX指数なども下落。ブラジルボベスパ指数は上昇。MSCI WORLDは3,893.65ドル（前日比-13.17ドル）、MSCI EMは1,132.45ドル（前日比-4.42ドル）。 主要国債:  日本10年国債利回りは、2025年2月17日時点での数値は記載なし。米国、ドイツ、オーストラリアの10年国債利回りの数値は記載されているが、具体的な数値は提示されていません。グラフで確認する必要がある。 主要通貨:  米ドル/円は149.64円（前日比▲1.21円）、ユーロ/円は157.16円（前日比▲0.46円）。その他の主要通貨（英ポンド、カナダドル、豪ドル、NZドル、シンガポールドル、中国人民元、インド ルピー、インドネシアルピア、メキシコペソ、ブラジルレアル、トルコリラ、ロシアルーブル）に対円の為替レートと前日比の変動率が示されている。 商品: WTI原油先物は72.57ドル（前日比+0.32ドル）、COMEX金先物は2,940.00ドル（前日比+20.60ドル）。2. 主要国株式の動き上記「主要金融市場の動き」の主要国株式のセクションを参照。3. マーケットの動き 日本: 円高進行や日銀追加利上げ観測を嫌気し、日本株は軟調。1月消費者物価の上振れリスクへの警戒感も。 米国: ウォルマートの業績見通し予想下回ることで消費の先行き不安を意識し、米国株は軟調。スタグフレーションリスクも指摘されている。 中国: 中国人民銀行は、最優遇貸出金利を予想通り据え置き。 豪州: 1月雇用統計で失業率上昇も、就業者数は予想を大幅に上回り、豪ドルは底堅い。 ユーロ圏: 2月消費者信頼感指数が2カ月連続上昇し、ユーロは対米ドルで上昇。4. 本日の注目点米欧の製造業回復の動きが一時的なものか、持続的なものかが注目されている。2月購買担当者景気指数（PMI）速報で製造業の動向が注目される。米国が2カ月連続で50超え、ユーロ圏とドイツも2カ月連続上昇となれば、製造業回復が持続的な動きであるとの見方が強まり、景気楽観論を下支えする可能性がある。'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIR = \"input/data-rag/\"\n",
    "extract_text_from_pdf(INPUT_DIR + \"daily250221.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "615f8345-bfd0-4763-bbe0-8570feeb28c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 主要金融市場の動き 株式市場: 2月14日時点では、日経平均株価は+0.93%、TOPIXは+0.80%、NYダウは+0.55%、S&P500は+1.47%、ナスダック総合指数は+2.58%上昇。ストックス・ヨーロッパ600は+1.78%、DAX指数は+3.33%上昇。中国上海総合指数は+1.30%上昇。MSCI WORLDは+1.72%、MSCI EMは+1.51%上昇。S&P先進国REIT指数は+0.54%、東証REIT指数は+0.26%上昇。 長期金利（10年国債利回り）: 日本は1.350%、米国は4.477%、ドイツは2.431%、フランスは3.173%、イタリアは3.522%、スペインは3.061%、英国は4.500%、カナダは3.109%、オーストラリアは4.417%。 為替相場（対円）: 米ドルは152.31円(+0.59%)、ユーロは159.83円(+2.21%)、英ポンドは191.69円(+2.09%)、カナダドルは107.44円(+1.44%)、オーストラリアドルは96.74円(+1.88%)上昇。中国人民元は20.986円(+1.13%)上昇。 商品: 原油(WTI先物)は70.74ドル(-0.37%)、金(COMEX先物)は2,883.60ドル(+0.57%)。2. 主要国株式の動き 日本: 日経平均株価は3週ぶりに反発し、+0.9%上昇。輸出関連銘柄を中心に買いが優勢で、好調な企業決算も追い風となった。 米国: S&P500は3週ぶりに上昇し、週間で+1.47%と史上最高値に近づいた。1月CPIの上振れで一時下押す場面もあったが、トランプ政権の姿勢を市場は好感。 欧州: ストックス・ヨーロッパ600指数は史上最高値を更新。堅調な企業決算や、トランプ政権の相互関税の即時発効回避、ロシア・ウクライナの停戦期待などが市場心理の改善につながった。ドイツDAX指数も大幅上昇。 中国: 上海総合指数は上昇。 英国: 10-12月期の実質GDPは予想外にプラス成長となったが、個人消費や設備投資の弱さが懸念材料。3. マーケットの動き 株式市場は、米国を中心とした主要国の雇用環境の安定、消費主導の景気回復基調を背景に堅調を維持しているものの、米利下げ期待の後退、貿易摩擦や地政学リスクへの警戒感から、悪材料に過敏になっている。 主要国製造業の回復の兆しが見られるものの、それが持続的なのか、一時的なのかは今後の景気指標次第。 インフレは下げ渋り傾向。 ユーロ圏の投資家センチメント指数は改善し、景気回復への期待が高まっているが、先行き不透明感は依然として強い。 インドネシアは景気が堅調だが、今年前半は一時的に鈍化する可能性。4. 本日の注目点今週発表される主要経済指標は以下の通り。特に★印は注目度が高い。 2/17（日）:  日本 10-12月期 実質GDP（1次速報） 2/18（火）: ★米国 2月ニューヨーク連銀製造業景気指数、★オーストラリア金融政策決定会合（結果公表） 2/19（水）: ★米国 FOMC議事録（1月28-29日分） 2/20（木）: ★米国 2月フィラデルフィア連銀製造業景気指数、米国新規失業保険申請件数 2/21（金）: ★日本 1月消費者物価、日本 2月製造業PMI（速報）、★米国 2月製造業PMI（速報）、★米国 2月サービス業PMI（速報）、★ユーロ圏 2月製造業PMI（速報）、★ドイツ 2月製造業PMI（速報） 2/23（日）: ★ドイツ総選挙その他、日本国内では1月貿易統計、1月全国消費者物価、日銀の早期利上げへの警戒感、ドイツでは総選挙の結果が注目される。上記の情報は提示されたテキストに基づいており、全ての内容を網羅しているとは限りません。また、予想値が含まれるため、実際の結果とは異なる可能性があります。'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_from_pdf(INPUT_DIR + \"250217_weekly.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0e1a26c-9ec7-4e9b-bef6-e5c9e2267a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "import os\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ✅ ChromaDBのコンテナへHTTP接続\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)  # chromadbのサービス名を使う\n",
    "\n",
    "# コレクションを取得・作成\n",
    "collection = client.get_or_create_collection(\"rag_docs\")\n",
    "\n",
    "def get_gemini_embedding(text):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    model = genai.GenerativeModel(\"embedding-001\")\n",
    "    response = model.embed_content(text, task_type=\"retrieval_document\")\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def add_document(text, source):\n",
    "    \"\"\"ChromaDBに埋め込みデータを登録\"\"\"\n",
    "    embedding = get_gemini_embedding(text)\n",
    "    collection.add(documents=[text], metadatas=[{\"source\": source}], embeddings=[embedding])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3cc68108-0f9d-4691-a825-129adf39ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ✅ モデル一覧をリストとして出力\n",
    "models = list(genai.list_models())\n",
    "\n",
    "# 各モデルの情報を表示\n",
    "#for model in models:\n",
    "#    print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d1871f5-9756-4198-8947-3a9c8bc1e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 追加完了: テストデータ (ID: e44f8cec-ec35-489b-9f7e-fd2603d68851)\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "import os\n",
    "import uuid  # ✅ 一意のIDを生成するために追加\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ChromaDB クライアントを作成\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)  # ChromaDB のサービス名を使う\n",
    "collection = client.get_or_create_collection(\"rag_docs\")\n",
    "\n",
    "def get_gemini_embedding(text):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    response = genai.embed_content(model=\"models/text-embedding-004\", content=text)  # ✅ 修正\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def add_document(text, source):\n",
    "    \"\"\"ChromaDBに埋め込みデータを登録\"\"\"\n",
    "    embedding = get_gemini_embedding(text)\n",
    "    doc_id = str(uuid.uuid4())  # ✅ 一意のIDを生成\n",
    "    collection.add(ids=[doc_id], documents=[text], metadatas=[{\"source\": source}], embeddings=[embedding])\n",
    "    print(f\"✅ 追加完了: {source} (ID: {doc_id})\")\n",
    "\n",
    "# ✅ 動作確認テスト\n",
    "test_text = \"これはテスト用のドキュメントです。\"\n",
    "test_source = \"テストデータ\"\n",
    "add_document(test_text, test_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3bbbe04-071b-4b19-8a25-a148c4e038df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 類似ドキュメント: これはテスト用のドキュメントです。\n",
      "   🔹 メタデータ: {'source': 'テストデータ'}\n",
      "   🔹 類似度スコア: 0.0\n",
      "--------------------------------------------------\n",
      "📌 類似ドキュメント: 自然言語処理はテキストデータの分析に役立ちます。\n",
      "   🔹 メタデータ: {'source': '技術記事3'}\n",
      "   🔹 類似度スコア: 0.0\n",
      "--------------------------------------------------\n",
      "📌 類似ドキュメント: 経済学では市場の動きを分析する。\n",
      "   🔹 メタデータ: {'source': '経済ニュース1'}\n",
      "   🔹 類似度スコア: 0.0\n",
      "--------------------------------------------------\n",
      "📌 類似ドキュメント: 株式市場の動向は投資家にとって重要な指標だ。\n",
      "   🔹 メタデータ: {'source': '経済ニュース2'}\n",
      "   🔹 類似度スコア: 0.0\n",
      "--------------------------------------------------\n",
      "📌 類似ドキュメント: データサイエンスとは、データを活用した分析手法のこと。\n",
      "   🔹 メタデータ: {'source': '技術記事1'}\n",
      "   🔹 類似度スコア: 0.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def search_similar_documents(query_text, n_results=5):\n",
    "    \"\"\"ChromaDBに保存されている文書と類似するものを検索\"\"\"\n",
    "    query_embedding = get_gemini_embedding(query_text)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "\n",
    "    for doc, metadata, score in zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0]):\n",
    "        print(f\"📌 類似ドキュメント: {doc}\")\n",
    "        print(f\"   🔹 メタデータ: {metadata}\")\n",
    "        print(f\"   🔹 類似度スコア: {score}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# ✅ 検索テスト\n",
    "search_query = \"テスト用の文章\"\n",
    "search_similar_documents(search_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49990630-9ea9-44ab-8fed-5995561f2088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 データ追加テスト\n",
      "✅ 追加完了: 技術記事1 (ID: 9a7e8400-8eec-4642-9546-9c023db72ced)\n",
      "✅ 追加完了: 技術記事2 (ID: ac445604-8fa8-4005-9802-40c2c89ecd10)\n",
      "✅ 追加完了: 経済ニュース1 (ID: cf0e8a55-6ee7-43ad-8245-6bb619c792a1)\n",
      "✅ 追加完了: 経済ニュース2 (ID: b256bd46-f57b-47c6-9c80-686a616ae4be)\n",
      "✅ 追加完了: 技術記事3 (ID: c946ea37-a41c-4924-a03f-6f0ed53cedc6)\n",
      "\n",
      "📌 検索テスト（類似するニュースを検索）: データサイエンス\n",
      "\n",
      "📌 検索結果:\n",
      "🔹 1. 類似ドキュメント: ディープラーニングはニューラルネットワークを活用します。\n",
      "   🔹 メタデータ: {'source': '技術記事2'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n",
      "🔹 2. 類似ドキュメント: 為替相場の変動は経済全体に影響を与えます。\n",
      "   🔹 メタデータ: {'source': '経済ニュース2'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n",
      "🔹 3. 類似ドキュメント: 自然言語処理はテキストデータの分析に役立ちます。\n",
      "   🔹 メタデータ: {'source': '技術記事3'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ✅ ChromaDBのコンテナへHTTP接続\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "collection = client.get_or_create_collection(\"rag_docs\")\n",
    "\n",
    "def get_gemini_embedding(text, model_name=\"models/text-embedding-004\"):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    model = genai.GenerativeModel(\"models/text-embedding-004\")\n",
    "#    response = model.embed_content(text)  # ✅ embedContent の修正\n",
    "    response = genai.embed_content(model=\"models/text-embedding-004\", content=text)  # ✅ 修正\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def add_document(text, source):\n",
    "    \"\"\"ChromaDBに埋め込みデータを登録\"\"\"\n",
    "    embedding = get_gemini_embedding(text)\n",
    "    doc_id = str(uuid.uuid4())  # 一意のIDを作成\n",
    "    collection.add(documents=[text], metadatas=[{\"source\": source}], embeddings=[embedding], ids=[doc_id])\n",
    "    print(f\"✅ 追加完了: {source} (ID: {doc_id})\")\n",
    "\n",
    "# ✅ 1. データ登録テスト\n",
    "test_data = [\n",
    "    (\"機械学習はデータサイエンスの一部です。\", \"技術記事1\"),\n",
    "    (\"ディープラーニングはニューラルネットワークを活用します。\", \"技術記事2\"),\n",
    "    (\"金融市場は日々変動する。\", \"経済ニュース1\"),\n",
    "    (\"為替相場の変動は経済全体に影響を与えます。\", \"経済ニュース2\"),\n",
    "    (\"自然言語処理はテキストデータの分析に役立ちます。\", \"技術記事3\"),\n",
    "]\n",
    "\n",
    "print(\"\\n📌 データ追加テスト\")\n",
    "for text, source in test_data:\n",
    "    add_document(text, source)\n",
    "\n",
    "# ✅ 2. 検索テスト\n",
    "search_query = \"データサイエンス\"\n",
    "print(f\"\\n📌 検索テスト（類似するニュースを検索）: {search_query}\")\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[get_gemini_embedding(search_query)],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "# ✅ 3. 検索結果の表示\n",
    "print(\"\\n📌 検索結果:\")\n",
    "for i, (doc, meta, score) in enumerate(zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0])):\n",
    "    print(f\"🔹 {i+1}. 類似ドキュメント: {doc}\")\n",
    "    print(f\"   🔹 メタデータ: {meta}\")\n",
    "    print(f\"   🔹 類似度スコア: {score:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3879755a-ed4a-451f-b4cd-2e6cb7808cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 データ追加テスト\n",
      "✅ 追加完了: 技術記事1 (ID: 5a06f535-273a-4633-b0ae-f1545f23f519)\n",
      "✅ 追加完了: 技術記事2 (ID: 320ea2d4-0a9a-4b10-bec3-8b109bf77195)\n",
      "✅ 追加完了: 技術記事3 (ID: 9960a008-d78b-4e4c-a47f-e8b24f11b5c5)\n",
      "✅ 追加完了: 経済ニュース1 (ID: 9c24699d-8674-41c3-ad6a-2d18eac1e9c0)\n",
      "✅ 追加完了: 経済ニュース2 (ID: 78d6f336-4f4f-4357-b7d0-482cabc928ae)\n",
      "\n",
      "📌 検索テスト（類似するニュースを検索）: 家事について\n",
      "\n",
      "📌 検索結果:\n",
      "🔹 1. 類似ドキュメント: これはテスト用のドキュメントです。\n",
      "   🔹 メタデータ: {'source': 'テストデータ'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n",
      "🔹 2. 類似ドキュメント: データサイエンスとは、データを活用した分析手法のこと。\n",
      "   🔹 メタデータ: {'source': '技術記事1'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n",
      "🔹 3. 類似ドキュメント: 株式市場の動向は投資家にとって重要な指標だ。\n",
      "   🔹 メタデータ: {'source': '経済ニュース2'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ✅ ChromaDBのコンテナへHTTP接続\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "collection = client.get_or_create_collection(\"rag_docs\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "def get_gemini_embedding(text, model_name=\"models/embedding-001\"):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    response = genai.embed_content(model=\"models/text-embedding-004\", content=text)  # ✅ 修正\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def add_document(text, source):\n",
    "    \"\"\"ChromaDBに埋め込みデータを登録\"\"\"\n",
    "    embedding = get_gemini_embedding(text)\n",
    "    doc_id = str(uuid.uuid4())  # 一意のIDを作成\n",
    "    collection.add(documents=[text], metadatas=[{\"source\": source}], embeddings=[embedding], ids=[doc_id])\n",
    "    print(f\"✅ 追加完了: {source} (ID: {doc_id})\")\n",
    "\n",
    "# ✅ 1. データ登録テスト（データを増やす）\n",
    "test_data = [\n",
    "    (\"データサイエンスとは、データを活用した分析手法のこと。\", \"技術記事1\"),\n",
    "    (\"機械学習は統計と計算機科学の融合である。\", \"技術記事2\"),\n",
    "    (\"ニューラルネットワークは脳の構造を模倣する。\", \"技術記事3\"),\n",
    "    (\"経済学では市場の動きを分析する。\", \"経済ニュース1\"),\n",
    "    (\"株式市場の動向は投資家にとって重要な指標だ。\", \"経済ニュース2\"),\n",
    "]\n",
    "\n",
    "print(\"\\n📌 データ追加テスト\")\n",
    "for text, source in test_data:\n",
    "    add_document(text, source)\n",
    "\n",
    "# ✅ 2. 検索テスト\n",
    "search_query = \"データサイエンス\"\n",
    "print(f\"\\n📌 検索テスト（類似するニュースを検索）: {search_query}\")\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[get_gemini_embedding(search_query)],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "# ✅ 3. 検索結果の表示\n",
    "print(\"\\n📌 検索結果:\")\n",
    "for i, (doc, meta, score) in enumerate(zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0])):\n",
    "    print(f\"🔹 {i+1}. 類似ドキュメント: {doc}\")\n",
    "    print(f\"   🔹 メタデータ: {meta}\")\n",
    "    print(f\"   🔹 類似度スコア: {score:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6bfa2c67-30c0-4848-a5b2-faae62e7cfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 データ追加テスト\n",
      "✅ 追加完了: 技術記事1 (ID: c036578b-4796-4887-a6a8-975fd6ffc75a)\n",
      "✅ 追加完了: 技術記事2 (ID: c78d3fc7-f577-489c-9a83-24895a698420)\n",
      "✅ 追加完了: 技術記事3 (ID: c589b008-2968-4100-9320-1c144ec921cf)\n",
      "✅ 追加完了: 技術記事4 (ID: eab9530e-d05e-4b85-b5e4-2b33ad9ff3f5)\n",
      "✅ 追加完了: 経済ニュース1 (ID: 1c60ed29-aa27-4d3e-975e-80af6588ddfc)\n",
      "✅ 追加完了: 経済ニュース2 (ID: 539a0216-3fdd-441b-8126-6d509dc6084e)\n",
      "\n",
      "📌 検索テスト（類似するニュースを検索）: データ分析\n",
      "\n",
      "📌 検索結果:\n",
      "🔹 1. 類似ドキュメント: これはテスト用のドキュメントです。\n",
      "   🔹 メタデータ: {'source': 'テストデータ'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n",
      "🔹 2. 類似ドキュメント: データサイエンスとは、データを活用した分析手法のこと。\n",
      "   🔹 メタデータ: {'source': '技術記事1'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n",
      "🔹 3. 類似ドキュメント: 株式市場の動向は投資家にとって重要な指標だ。\n",
      "   🔹 メタデータ: {'source': '経済ニュース2'}\n",
      "   🔹 類似度スコア: 0.0000\n",
      "\n",
      "\n",
      "📊 埋め込みベクトルの統計情報:\n",
      "   平均値: -0.0011, 標準偏差: 0.0080\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ✅ ChromaDBのコンテナへHTTP接続\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "collection = client.get_or_create_collection(\"rag_docs\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "def get_gemini_embedding(text, model_name=\"models/embedding-001\"):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    response = genai.embed_content(model=\"models/text-embedding-004\", content=text)  # ✅ 修正\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def add_document(text, source):\n",
    "    \"\"\"ChromaDBに埋め込みデータを登録\"\"\"\n",
    "    embedding = get_gemini_embedding(text)\n",
    "    doc_id = str(uuid.uuid4())  # 一意のIDを作成\n",
    "    collection.add(documents=[text], metadatas=[{\"source\": source}], embeddings=[embedding], ids=[doc_id])\n",
    "    print(f\"✅ 追加完了: {source} (ID: {doc_id})\")\n",
    "\n",
    "# ✅ 1. データ登録テスト（類似データを増やす）\n",
    "test_data = [\n",
    "    (\"データサイエンスとは、データを活用した分析手法のこと。\", \"技術記事1\"),\n",
    "    (\"データサイエンスは機械学習と統計の融合です。\", \"技術記事2\"),  # 類似データ\n",
    "    (\"ニューラルネットワークはAIの中心技術の一つです。\", \"技術記事3\"),\n",
    "    (\"データ解析の手法には回帰分析やクラスタリングがあります。\", \"技術記事4\"),  # 類似データ\n",
    "    (\"経済学では市場の動きを分析する。\", \"経済ニュース1\"),\n",
    "    (\"為替市場の変動は経済全体に影響を与えます。\", \"経済ニュース2\"),\n",
    "]\n",
    "\n",
    "print(\"\\n📌 データ追加テスト\")\n",
    "for text, source in test_data:\n",
    "    add_document(text, source)\n",
    "\n",
    "# ✅ 2. 検索テスト\n",
    "search_query = \"データ分析\"\n",
    "print(f\"\\n📌 検索テスト（類似するニュースを検索）: {search_query}\")\n",
    "\n",
    "query_embedding = get_gemini_embedding(search_query)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "# ✅ 3. 検索結果の表示\n",
    "print(\"\\n📌 検索結果:\")\n",
    "for i, (doc, meta, score) in enumerate(zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0])):\n",
    "    print(f\"🔹 {i+1}. 類似ドキュメント: {doc}\")\n",
    "    print(f\"   🔹 メタデータ: {meta}\")\n",
    "    print(f\"   🔹 類似度スコア: {score:.4f}\\n\")\n",
    "\n",
    "# ✅ 4. 埋め込みベクトルの分布を確認\n",
    "all_embeddings = np.array([get_gemini_embedding(text) for text, _ in test_data] + [query_embedding])\n",
    "mean_vector = np.mean(all_embeddings, axis=0)\n",
    "std_dev_vector = np.std(all_embeddings, axis=0)\n",
    "\n",
    "print(\"\\n📊 埋め込みベクトルの統計情報:\")\n",
    "print(f\"   平均値: {np.mean(mean_vector):.4f}, 標準偏差: {np.mean(std_dev_vector):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95125998-3b75-4ac4-b6a3-7e1c0af16d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in /opt/conda/lib/python3.11/site-packages (0.11.5)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in /opt/conda/lib/python3.11/site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.11/site-packages (from pdfplumber) (10.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /opt/conda/lib/python3.11/site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2582c3da-5c4f-4935-8141-5dcdb43f3659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['88e2d6d5-f77d-4a0c-8663-17ef0a9e561b',\n",
       "   '62db6eff-6782-40e2-a4a5-ac688cd1be55']],\n",
       " 'distances': [[0.18927793204784393, 0.18927793204784393]],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [[{'source': 'テストデータ'}, {'source': '技術記事1'}]],\n",
       " 'documents': [['これはテスト用のドキュメントです。', 'データサイエンスとは、データを活用した分析手法のこと。']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['distances', 'documents', 'metadatas']}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aede9335-42a9-4ea2-be1b-08863c46d338",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidCollectionException",
     "evalue": "Collection af98fc14-4183-4ee5-a30f-cb07ad5f6cee does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidCollectionException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/api/models/Collection.py:160\u001b[0m, in \u001b[0;36mCollection.peek\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpeek\u001b[39m(\u001b[38;5;28mself\u001b[39m, limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GetResult:\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the first few results in the database up to limit\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m        GetResult: A GetResult object containing the results.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_peek_response(\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_peek\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/api/fastapi.py:344\u001b[0m, in \u001b[0;36mFastAPI._peek\u001b[0;34m(self, collection_id, n, tenant, database)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFastAPI._peek\u001b[39m\u001b[38;5;124m\"\u001b[39m, OpenTelemetryGranularity\u001b[38;5;241m.\u001b[39mOPERATION)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_peek\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m     database: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[1;32m    341\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GetResult:\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    343\u001b[0m         GetResult,\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m            \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[list-item]\u001b[39;49;00m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    351\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/api/fastapi.py:374\u001b[0m, in \u001b[0;36mFastAPI._get\u001b[0;34m(self, collection_id, ids, where, sort, limit, offset, page, page_size, where_document, include, tenant, database)\u001b[0m\n\u001b[1;32m    371\u001b[0m     offset \u001b[38;5;241m=\u001b[39m (page \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m page_size\n\u001b[1;32m    372\u001b[0m     limit \u001b[38;5;241m=\u001b[39m page_size\n\u001b[0;32m--> 374\u001b[0m resp_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tenants/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtenant\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/databases/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatabase\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcollection_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/get\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlimit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GetResult(\n\u001b[1;32m    389\u001b[0m     ids\u001b[38;5;241m=\u001b[39mresp_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    390\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39mresp_json\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m     included\u001b[38;5;241m=\u001b[39mresp_json\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincluded\u001b[39m\u001b[38;5;124m\"\u001b[39m, include),\n\u001b[1;32m    396\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/api/fastapi.py:90\u001b[0m, in \u001b[0;36mFastAPI._make_request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_url \u001b[38;5;241m+\u001b[39m escaped_path\n\u001b[1;32m     89\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcast(Any, kwargs))\n\u001b[0;32m---> 90\u001b[0m \u001b[43mBaseHTTPClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_chroma_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m orjson\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/api/base_http_client.py:96\u001b[0m, in \u001b[0;36mBaseHTTPClient._raise_chroma_error\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chroma_error:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m chroma_error\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mInvalidCollectionException\u001b[0m: Collection af98fc14-4183-4ee5-a30f-cb07ad5f6cee does not exist."
     ]
    }
   ],
   "source": [
    "collection.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5031881c-0d64-41b3-985f-5cfe8c6674a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['88e2d6d5-f77d-4a0c-8663-17ef0a9e561b', '62db6eff-6782-40e2-a4a5-ac688cd1be55']], 'distances': [[0.18927793204784393, 0.18927793204784393]], 'embeddings': None, 'metadatas': [[{'source': 'テストデータ'}, {'source': '技術記事1'}]], 'documents': [['これはテスト用のドキュメントです。', 'データサイエンスとは、データを活用した分析手法のこと。']], 'uris': None, 'data': None, 'included': ['distances', 'documents', 'metadatas']}\n"
     ]
    }
   ],
   "source": [
    "def get_gemini_embedding(text):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    response = genai.embed_content(model=\"models/text-embedding-004\", content=text)  # ✅ 768次元のモデルを指定\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "query_text = \"機械学習って何？\"\n",
    "query_embedding = get_gemini_embedding(query_text)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],  # ✅ クエリを埋め込みベクトルに変換して送る\n",
    "    n_results=2\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114806f-e99c-4fc0-8011-7acb87f857ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e32c7c53-7817-4c4d-a3ad-bf9fe5f54ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 登録完了: input/data-rag/daily250221.pdf → daily (ID: 0f0924ba-c58c-4293-a43a-b1a562ab5ade)\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Request payload size exceeds the limit: 10000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 67\u001b[0m\n\u001b[1;32m     59\u001b[0m pdf_files \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     60\u001b[0m     INPUT_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily250221.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m     INPUT_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweekly_exchange.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweekly\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#    \"sample_news.pdf\": \"news\",\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#    \"sample_other.pdf\": \"other\",\u001b[39;00m\n\u001b[1;32m     64\u001b[0m }\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file, category \u001b[38;5;129;01min\u001b[39;00m pdf_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 67\u001b[0m     \u001b[43mprocess_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 41\u001b[0m, in \u001b[0;36mprocess_pdf\u001b[0;34m(file_path, category)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m はテキストを抽出できませんでした\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mget_gemini_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m doc_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())  \u001b[38;5;66;03m# ユニークなIDを生成\u001b[39;00m\n\u001b[1;32m     44\u001b[0m collections[category]\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m     45\u001b[0m     ids\u001b[38;5;241m=\u001b[39m[doc_id],\n\u001b[1;32m     46\u001b[0m     documents\u001b[38;5;241m=\u001b[39m[full_text],\n\u001b[1;32m     47\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m: category}],\n\u001b[1;32m     48\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39m[embedding]\n\u001b[1;32m     49\u001b[0m )\n",
      "Cell \u001b[0;32mIn[40], line 28\u001b[0m, in \u001b[0;36mget_gemini_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/text-embedding-004\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 適切な埋め込みモデルを選択\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/text-embedding-004\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ✅ 修正\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/generativeai/embedding.py:213\u001b[0m, in \u001b[0;36membed_content\u001b[0;34m(model, content, task_type, title, output_dimensionality, client, request_options)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     embedding_request \u001b[38;5;241m=\u001b[39m protos\u001b[38;5;241m.\u001b[39mEmbedContentRequest(\n\u001b[1;32m    207\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    208\u001b[0m         content\u001b[38;5;241m=\u001b[39mcontent_types\u001b[38;5;241m.\u001b[39mto_content(content),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m         output_dimensionality\u001b[38;5;241m=\u001b[39moutput_dimensionality,\n\u001b[1;32m    212\u001b[0m     )\n\u001b[0;32m--> 213\u001b[0m     embedding_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     embedding_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(embedding_response)\u001b[38;5;241m.\u001b[39mto_dict(embedding_response)\n\u001b[1;32m    218\u001b[0m     embedding_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m embedding_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:1263\u001b[0m, in \u001b[0;36mGenerativeServiceClient.embed_content\u001b[0;34m(self, request, model, content, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1263\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Request payload size exceeds the limit: 10000 bytes."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import chromadb\n",
    "import google.generativeai as genai\n",
    "import uuid\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ChromaDB の HTTP クライアント（Docker コンテナの chromadb に接続）\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "\n",
    "# ✅ コレクション作成（用途別）\n",
    "collections = {\n",
    "    \"daily\": client.get_or_create_collection(\"daily_docs\"),\n",
    "    \"weekly\": client.get_or_create_collection(\"weekly_docs\"),\n",
    "}\n",
    "\n",
    "# ✅ テキストの埋め込み取得関数\n",
    "def get_gemini_embedding(text):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    model = genai.GenerativeModel(\"models/text-embedding-004\")  # 適切な埋め込みモデルを選択\n",
    "    response = genai.embed_content(model=\"models/text-embedding-004\", content=text)  # ✅ 修正\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "# ✅ PDFのテキストを用途別に登録\n",
    "def process_pdf(file_path, category):\n",
    "    \"\"\"PDFファイルを読み込んで用途別にChromaDBへ登録\"\"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    \n",
    "    if not full_text.strip():\n",
    "        print(f\"⚠️ {file_path} はテキストを抽出できませんでした\")\n",
    "        return\n",
    "    \n",
    "    embedding = get_gemini_embedding(full_text)\n",
    "    doc_id = str(uuid.uuid4())  # ユニークなIDを生成\n",
    "\n",
    "    collections[category].add(\n",
    "        ids=[doc_id],\n",
    "        documents=[full_text],\n",
    "        metadatas=[{\"source\": file_path, \"category\": category}],\n",
    "        embeddings=[embedding]\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ 登録完了: {file_path} → {category} (ID: {doc_id})\")\n",
    "\n",
    "INPUT_DIR = \"input/data-rag/\"\n",
    "extract_text_from_pdf(INPUT_DIR + \"daily250221.pdf\")\n",
    "\n",
    "extract_text_from_pdf(INPUT_DIR + \"weekly_exchange.pdf\")\n",
    "\n",
    "# ✅ テスト用PDFの登録（用途に応じて変更）\n",
    "pdf_files = {\n",
    "    INPUT_DIR + \"daily250221.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"weekly_exchange.pdf\": \"weekly\",\n",
    "#    \"sample_news.pdf\": \"news\",\n",
    "#    \"sample_other.pdf\": \"other\",\n",
    "}\n",
    "\n",
    "for file, category in pdf_files.items():\n",
    "    process_pdf(file, category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78f5ebba-f1d1-4603-8ba8-4252397e01b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ チャンク 1/2 登録完了: input/data-rag/daily250221.pdf → daily (ID: dc09b480-5b88-4bb7-8614-e672be0b6f7c)\n",
      "✅ チャンク 2/2 登録完了: input/data-rag/daily250221.pdf → daily (ID: cdf406a4-a5e9-4d7a-bc10-8fdd3ad0a30b)\n",
      "✅ チャンク 1/2 登録完了: input/data-rag/daily250220.pdf → daily (ID: 3bd06dd7-831d-404f-b67e-c9a97d820b54)\n",
      "✅ チャンク 2/2 登録完了: input/data-rag/daily250220.pdf → daily (ID: da09d035-3443-49c1-aa88-76f33ff9ebd6)\n",
      "✅ チャンク 1/2 登録完了: input/data-rag/daily250219.pdf → daily (ID: 3af5b42d-f02e-4641-9293-66215a26a2b4)\n",
      "✅ チャンク 2/2 登録完了: input/data-rag/daily250219.pdf → daily (ID: a50b469d-215e-4d7e-a066-63113f49bece)\n",
      "✅ チャンク 1/2 登録完了: input/data-rag/daily250218.pdf → daily (ID: c2fd902b-8567-4270-acb6-e6334191f11c)\n",
      "✅ チャンク 2/2 登録完了: input/data-rag/daily250218.pdf → daily (ID: 28f79faf-4920-4c7f-b025-b23ad3e379b3)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/data-rag/daily250217.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 101\u001b[0m\n\u001b[1;32m     88\u001b[0m pdf_files \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     89\u001b[0m     INPUT_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily250221.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m     INPUT_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily250220.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     INPUT_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonthly_2502.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonthly\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m }\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file, category \u001b[38;5;129;01min\u001b[39;00m pdf_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 101\u001b[0m     \u001b[43mprocess_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[74], line 56\u001b[0m, in \u001b[0;36mprocess_pdf\u001b[0;34m(file_path, category)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ 未知のカテゴリ \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m を \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m に変更\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m     category \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpdfplumber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m     57\u001b[0m     full_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([page\u001b[38;5;241m.\u001b[39mextract_text() \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf\u001b[38;5;241m.\u001b[39mpages \u001b[38;5;28;01mif\u001b[39;00m page\u001b[38;5;241m.\u001b[39mextract_text()])\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m full_text\u001b[38;5;241m.\u001b[39mstrip():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pdfplumber/pdf.py:95\u001b[0m, in \u001b[0;36mPDF.open\u001b[0;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, unicode_norm, repair, gs_path, repair_setting, raise_unicode_errors)\u001b[0m\n\u001b[1;32m     93\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[0;32m---> 95\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(path_or_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m     stream_is_external \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path_or_fp)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/data-rag/daily250217.pdf'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import chromadb\n",
    "import google.generativeai as genai\n",
    "import uuid\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ChromaDB の HTTP クライアント（Docker コンテナの chromadb に接続）\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "\n",
    "# ✅ コレクション作成\n",
    "collections = {\n",
    "    \"daily\": client.get_or_create_collection(\"daily_docs\"),\n",
    "    \"weekly\": client.get_or_create_collection(\"weekly_docs\"),\n",
    "    \"monthly\": client.get_or_create_collection(\"monthly_docs\"),\n",
    "}\n",
    "\n",
    "# ✅ テキストの埋め込み取得関数（10,000バイト制限対応）\n",
    "def get_gemini_embedding(text):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"models/text-embedding-004\")  \n",
    "        response = genai.embed_content(model=\"models/text-embedding-004\", content=text)  # ✅ 修正\n",
    "        return response[\"embedding\"]\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 埋め込みエラー: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# ✅ バイト数でテキストを分割する関数\n",
    "def split_text_by_bytes(text, max_bytes=8000):\n",
    "    \"\"\"UTF-8エンコーディング時のバイト数に基づいてテキストを分割\"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in text.split(\"\\n\"):\n",
    "        if len((current_chunk + sentence).encode(\"utf-8\")) > max_bytes:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = sentence  # 新しいチャンク開始\n",
    "        else:\n",
    "            current_chunk += \"\\n\" + sentence\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# ✅ PDFのテキストを用途別に登録（チャンク分割対応）\n",
    "def process_pdf(file_path, category):\n",
    "    \"\"\"PDFファイルを読み込んで用途別にChromaDBへ登録（チャンク分割対応）\"\"\"\n",
    "    if category not in collections:\n",
    "        print(f\"⚠️ 未知のカテゴリ '{category}' を 'other' に変更\")\n",
    "        category = \"other\"\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    \n",
    "    if not full_text.strip():\n",
    "        print(f\"⚠️ {file_path} はテキストを抽出できませんでした\")\n",
    "        return\n",
    "    \n",
    "    # ✅ 8000バイト未満のチャンクに分割\n",
    "    text_chunks = split_text_by_bytes(full_text, max_bytes=8000)\n",
    "\n",
    "    for idx, chunk in enumerate(text_chunks):\n",
    "        embedding = get_gemini_embedding(chunk)\n",
    "        if embedding is None:\n",
    "            print(f\"⚠️ 埋め込み失敗: チャンク {idx+1}/{len(text_chunks)} (ファイル: {file_path})\")\n",
    "            continue\n",
    "\n",
    "        doc_id = str(uuid.uuid4())  # ユニークなIDを生成\n",
    "\n",
    "        try:\n",
    "            collections[category].add(\n",
    "                ids=[doc_id],\n",
    "                documents=[chunk],\n",
    "                metadatas=[{\"source\": file_path, \"category\": category, \"chunk_index\": idx}],\n",
    "                embeddings=[embedding]\n",
    "            )\n",
    "            print(f\"✅ チャンク {idx+1}/{len(text_chunks)} 登録完了: {file_path} → {category} (ID: {doc_id})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ChromaDB 登録エラー: {str(e)}\")\n",
    "\n",
    "# ✅ テスト用PDFの登録\n",
    "INPUT_DIR = \"input/data-rag/\"\n",
    "pdf_files = {\n",
    "    INPUT_DIR + \"daily250221.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"daily250220.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"daily250219.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"daily250218.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"250217_weekly.pdf\": \"weekly\",\n",
    "    INPUT_DIR + \"250210_weekly.pdf\": \"weekly\",\n",
    "    INPUT_DIR + \"250203_weekly.pdf\": \"weekly\",\n",
    "    INPUT_DIR + \"monthly_2502.pdf\": \"monthly\",\n",
    "}\n",
    "\n",
    "for file, category in pdf_files.items():\n",
    "    process_pdf(file, category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dbae8d2d-f073-4657-9497-44cc5ef9521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 登録されているコレクション:\n",
      "- weekly_docs\n",
      "- daily_docs\n",
      "- monthly_docs\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# ChromaDB クライアント（Docker の chromadb に接続）\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "\n",
    "# ✅ コレクション一覧を取得（修正後）\n",
    "collections = client.list_collections()\n",
    "print(\"📌 登録されているコレクション:\")\n",
    "for col in collections:\n",
    "    print(f\"- {col}\")  # `.name` は不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30172782-6278-4633-bfec-de3821dd0625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 コレクションの内容:\n",
      "\n",
      "🔹 ID: dc09b480-5b88-4bb7-8614-e672be0b6f7c\n",
      "📄 テキスト: \n",
      "D 情報提供資料\n",
      "投資環境デイリー\n",
      "2025年2月21日号\n",
      "経済調査室\n",
      "s\n",
      "u 米国株下落、米個人消費の先行き不安を意識\n",
      "c\n",
      "o\n",
      "F\n",
      "主要金融市場の動き 主要国株式の動き\n",
      "株式 （単位：ポイント） 2月20日 2月19日 前日差 48,000 （日経平均株価:円、NYダウ:米ドル） （DAX®:ポイント） 25,000\n",
      "日本 日経平均株価 （円） 38,678.04 39,164.61 -486...\n",
      "📝 メタデータ: {'category': 'daily', 'chunk_index': 0, 'source': 'input/data-rag/daily250221.pdf'}\n",
      "\n",
      "🔹 ID: cdf406a4-a5e9-4d7a-bc10-8fdd3ad0a30b\n",
      "📄 テキスト: ドイツ「DAX®」：本指数は、情報提供を目的としており、売買等を推奨するものではありません。\n",
      "FTSEInternationalLimited(“FTSE”)©FTSE。“FTSE®”はロンドン証券取引所グループ会社の登録商標であり、FTSEInternationalLimitedは許可を得\n",
      "て使用しています。FTSE指数、FTSE格付け、またはその両方におけるすべての権利は、FTSE、そのライセ...\n",
      "📝 メタデータ: {'category': 'daily', 'chunk_index': 1, 'source': 'input/data-rag/daily250221.pdf'}\n",
      "\n",
      "🔹 ID: 3bd06dd7-831d-404f-b67e-c9a97d820b54\n",
      "📄 テキスト: \n",
      "D 情報提供資料\n",
      "投資環境デイリー\n",
      "2025年2月20日号\n",
      "経済調査室\n",
      "s\n",
      "u 日欧株は下落、トランプ米政権の関税政策に警戒感\n",
      "c\n",
      "o\n",
      "F\n",
      "主要金融市場の動き 主要国株式の動き\n",
      "株式 （単位：ポイント） 2月19日 2月18日 前日差 46,000 （日経平均株価:円、NYダウ:米ドル） （DAX®:ポイント） 24,000\n",
      "日本 日経平均株価 （円） 39,164.61 39,270.40 -...\n",
      "📝 メタデータ: {'category': 'daily', 'chunk_index': 0, 'source': 'input/data-rag/daily250220.pdf'}\n",
      "\n",
      "🔹 ID: da09d035-3443-49c1-aa88-76f33ff9ebd6\n",
      "📄 テキスト: TOPIX（東証株価指数）、東証REIT指数に関する知的財産権その他一切の権利は株式会社JPX総研又は株式会社JPX総研の関連会社に帰属します。\n",
      "ドイツ「DAX®」：本指数は、情報提供を目的としており、売買等を推奨するものではありません。\n",
      "FTSEInternationalLimited(“FTSE”)©FTSE。“FTSE®”はロンドン証券取引所グループ会社の登録商標であり、FTSEIntern...\n",
      "📝 メタデータ: {'category': 'daily', 'chunk_index': 1, 'source': 'input/data-rag/daily250220.pdf'}\n",
      "\n",
      "🔹 ID: 3af5b42d-f02e-4641-9293-66215a26a2b4\n",
      "📄 テキスト: \n",
      "D 情報提供資料\n",
      "投資環境デイリー\n",
      "2025年2月19日号\n",
      "経済調査室\n",
      "s\n",
      "u 株式市場は続伸、ウクライナｰロシアの戦争終結への期待高まる\n",
      "c\n",
      "o\n",
      "F\n",
      "主要金融市場の動き 主要国株式の動き\n",
      "株式 （単位：ポイント） 2月18日 2月17日 前日差 （日経平均株価:円、NYダウ:米ドル） （DAX®:ポイント）\n",
      "46,000 24,000\n",
      "日本 日経平均株価 （円） 39,270.40 39,17...\n",
      "📝 メタデータ: {'category': 'daily', 'chunk_index': 0, 'source': 'input/data-rag/daily250219.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# ✅ コレクション名を指定して取得\n",
    "collection_name = \"daily_docs\"  # 確認したいコレクション名\n",
    "collection = client.get_collection(collection_name)\n",
    "\n",
    "# ✅ 登録されているドキュメントを取得（最初の5件）\n",
    "docs = collection.get(include=[\"documents\", \"metadatas\", \"embeddings\"], limit=5)\n",
    "\n",
    "print(\"\\n📌 コレクションの内容:\")\n",
    "for i, doc in enumerate(docs[\"documents\"]):\n",
    "    print(f\"\\n🔹 ID: {docs['ids'][i]}\")\n",
    "    print(f\"📄 テキスト: {doc[:200]}...\")  # 長すぎる場合は200文字に制限\n",
    "    print(f\"📝 メタデータ: {docs['metadatas'][i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7587257a-c6e0-4aea-aad0-c7e0a60ad3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weekly_docs', 'daily_docs', 'monthly_docs']\n"
     ]
    }
   ],
   "source": [
    "print(client.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "009d0287-44bd-4f5e-aebc-c107eb991a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# ChromaDB クライアント（Docker の chromadb に接続）\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "\n",
    "def retrieve_relevant_macro_info(query: str, collection_name=\"daily_docs\", top_k=3):\n",
    "    \"\"\"ChromaDBから最新のマクロ情報を取得\"\"\"\n",
    "    collection = client.get_collection(collection_name)\n",
    "    \n",
    "    # クエリに基づいて類似情報を検索\n",
    "    results = collection.query(\n",
    "        query_texts=[query], \n",
    "        n_results=top_k, \n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    # 検索結果のフォーマット\n",
    "    retrieved_docs = []\n",
    "    for i in range(len(results[\"documents\"])):\n",
    "        retrieved_docs.append(f\"🔹 {results['documents'][i][:200]}...\")  # 200文字に制限\n",
    "        retrieved_docs.append(f\"📝 {results['metadatas'][i]}\")\n",
    "\n",
    "    return \"\\n\".join(retrieved_docs) if retrieved_docs else \"🔍 関連情報なし\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db656e44-557f-494f-b7a0-db342d0e40b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChromaDB コレクション 'daily_docs' に接続しました！\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# ChromaDB の HTTP クライアント（Docker の chromadb に接続）\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "\n",
    "# 取得するコレクション名（用途に応じて変更）\n",
    "collection_name = \"daily_docs\"\n",
    "\n",
    "# ChromaDB からコレクションを取得\n",
    "collection = client.get_collection(collection_name)\n",
    "\n",
    "# 取得成功メッセージ\n",
    "print(f\"✅ ChromaDB コレクション '{collection_name}' に接続しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f2120-8d75-4697-bb83-ac1d1c829be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1aa1fccb-af52-4ef7-a451-63ebac2d44b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 🔥 ChromaDB RAG 検索結果 ===\n",
      "🔹 類似情報 1: \n",
      "D 情報提供資料\n",
      "投資環境デイリー\n",
      "2025年2月18日号\n",
      "経済調査室\n",
      "s\n",
      "u 日本の好調な経済成長を受けて国内金利上昇、円高の動き\n",
      "c\n",
      "o\n",
      "F\n",
      "主要金融市場の動き 主要国株式の動き\n",
      "株式 （単位：ポイント） 2月17日 2月14日 前日差 （日経平均株価:円、NYダウ:米ドル） （DAX®:ポイント）\n",
      "46,000 24,000\n",
      "日本 日経平均株価 （円） 39,174.25 39,149.4...\n",
      "📝 メタデータ: {'category': 'daily', 'chunk_index': 0, 'source': 'input/data-rag/daily250218.pdf'}\n",
      "🔢 類似度スコア: 0.9981\n",
      "--------------------------------------------------\n",
      "🔹 類似情報 2: \n",
      "D 情報提供資料\n",
      "投資環境デイリー\n",
      "2025年2月20日号\n",
      "経済調査室\n",
      "s\n",
      "u 日欧株は下落、トランプ米政権の関税政策に警戒感\n",
      "c\n",
      "o\n",
      "F\n",
      "主要金融市場の動き 主要国株式の動き\n",
      "株式 （単位：ポイント） 2月19日 2月18日 前日差 46,000 （日経平均株価:円、NYダウ:米ドル） （DAX®:ポイント） 24,000\n",
      "日本 日経平均株価 （円） 39,164.61 39,270.40 -...\n",
      "📝 メタデータ: {'category': 'daily', 'chunk_index': 0, 'source': 'input/data-rag/daily250220.pdf'}\n",
      "🔢 類似度スコア: 0.9997\n",
      "--------------------------------------------------\n",
      "🔹 類似情報 3: \n",
      "D 情報提供資料\n",
      "投資環境デイリー\n",
      "2025年2月19日号\n",
      "経済調査室\n",
      "s\n",
      "u 株式市場は続伸、ウクライナｰロシアの戦争終結への期待高まる\n",
      "c\n",
      "o\n",
      "F\n",
      "主要金融市場の動き 主要国株式の動き\n",
      "株式 （単位：ポイント） 2月18日 2月17日 前日差 （日経平均株価:円、NYダウ:米ドル） （DAX®:ポイント）\n",
      "46,000 24,000\n",
      "日本 日経平均株価 （円） 39,270.40 39,17...\n",
      "📝 メタデータ: {'category': 'daily', 'chunk_index': 0, 'source': 'input/data-rag/daily250219.pdf'}\n",
      "🔢 類似度スコア: 0.9998\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_gemini_embedding(text):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    response = genai.embed_content(model=\"models/text-embedding-004\", content=text)  # ✅ 768次元のモデルを指定\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def retrieve_relevant_info(query: str, top_k=3):\n",
    "    \"\"\"ChromaDB から類似情報を取得\"\"\"\n",
    "    query_embedding = get_gemini_embedding(query)  # ✅ クエリをベクトル化\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],  # ✅ クエリを埋め込みベクトルに変換して送る\n",
    "        n_results=top_k,  # 取得する類似データ数\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]  # 結果に含める情報\n",
    "    )\n",
    "\n",
    "    # 取得結果を整形\n",
    "    if not results[\"documents\"]:\n",
    "        return \"🔍 関連情報なし\"\n",
    "\n",
    "    retrieved_docs = []\n",
    "    for i in range(len(results[\"documents\"][0])):  # top_k の件数分ループ\n",
    "        retrieved_docs.append(f\"🔹 類似情報 {i+1}: {results['documents'][0][i][:200]}...\")\n",
    "        retrieved_docs.append(f\"📝 メタデータ: {results['metadatas'][0][i]}\")\n",
    "        retrieved_docs.append(f\"🔢 類似度スコア: {results['distances'][0][i]:.4f}\")\n",
    "        retrieved_docs.append(\"-\" * 50)\n",
    "\n",
    "    return \"\\n\".join(retrieved_docs)\n",
    "\n",
    "query_text = \"最近の金融市場動向\"\n",
    "retrieved_info = retrieve_relevant_info(query_text, top_k=3)\n",
    "\n",
    "print(\"\\n=== 🔥 ChromaDB RAG 検索結果 ===\")\n",
    "print(retrieved_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5b687291-7cdb-4d4b-b48f-f6421a845519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コレクションの削除\n",
    "client.delete_collection(\"daily_docs\")  # コレクション名を指定\n",
    "client.delete_collection(\"weekly_docs\")  # コレクション名を指定\n",
    "client.delete_collection(\"monthly_docs\")  # コレクション名を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef895d4e-def9-48e7-8e0e-0c7c0f43e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain)\n",
      "  Downloading langchain_core-0.3.38-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.10-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.22)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain) (9.0.0)\n",
      "Collecting numpy<2,>=1.26.4 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Downloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.38-py3-none-any.whl (414 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.10-py3-none-any.whl (333 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.0/333.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (14.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (276 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.4/232.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (340 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, propcache, numpy, multidict, frozenlist, aiohappyeyeballs, yarl, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.21.0\n",
      "    Uninstalling zstandard-0.21.0:\n",
      "      Successfully uninstalled zstandard-0.21.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiosignal-1.3.2 frozenlist-1.5.0 langchain-0.3.19 langchain-core-0.3.38 langchain-text-splitters-0.3.6 langsmith-0.3.10 multidict-6.1.0 numpy-1.26.4 propcache-0.3.0 requests-toolbelt-1.0.0 yarl-1.18.3 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a21da436-f1ec-46e8-ada7-e1bdaca5a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import chromadb\n",
    "import google.generativeai as genai\n",
    "import uuid\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 環境変数からAPIキーを設定\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ChromaDB の HTTP クライアント（Docker コンテナの chromadb に接続）\n",
    "client = chromadb.HttpClient(host=\"chromadb\", port=8000)\n",
    "\n",
    "# ✅ コレクション作成\n",
    "collections = {\n",
    "    \"daily\": client.get_or_create_collection(\"daily_docs\"),\n",
    "    \"weekly\": client.get_or_create_collection(\"weekly_docs\"),\n",
    "    \"monthly\": client.get_or_create_collection(\"monthly_docs\"),\n",
    "}\n",
    "\n",
    "# ✅ 適切な埋め込みモデルを利用\n",
    "EMBEDDING_MODEL = \"models/text-embedding-004\"  # 高精度な768次元埋め込み\n",
    "\n",
    "def get_gemini_embedding(text):\n",
    "    \"\"\"Gemini APIを使用してテキストの埋め込みを取得\"\"\"\n",
    "    try:\n",
    "        response = genai.embed_content(model=EMBEDDING_MODEL, content=text)\n",
    "        if \"embedding\" in response:\n",
    "            return response[\"embedding\"]\n",
    "        else:\n",
    "            print(f\"⚠️ 埋め込み取得失敗（レスポンス不正）: {response}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 埋め込みエラー: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# ✅ チャンク化（トークンベースで分割 & オーバーラップ設定）\n",
    "def split_text(text, chunk_size=300, overlap=50):\n",
    "    \"\"\"テキストを適切なチャンクサイズで分割\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=overlap, length_function=len\n",
    "    )\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "# ✅ PDFのテキストを用途別に登録（チャンク分割対応）\n",
    "def process_pdf(file_path, category):\n",
    "    \"\"\"PDFファイルを読み込んで用途別にChromaDBへ登録（チャンク分割対応）\"\"\"\n",
    "    if category not in collections:\n",
    "        print(f\"⚠️ 未知のカテゴリ '{category}' を 'other' に変更\")\n",
    "        category = \"other\"\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    \n",
    "    if not full_text.strip():\n",
    "        print(f\"⚠️ {file_path} はテキストを抽出できませんでした\")\n",
    "        return\n",
    "    \n",
    "    # ✅ トークンベースで分割\n",
    "    text_chunks = split_text(full_text)\n",
    "\n",
    "    for idx, chunk in enumerate(text_chunks):\n",
    "        embedding = get_gemini_embedding(chunk)\n",
    "        if embedding is None:\n",
    "            print(f\"⚠️ 埋め込み失敗: チャンク {idx+1}/{len(text_chunks)} (ファイル: {file_path})\")\n",
    "            continue\n",
    "\n",
    "        doc_id = str(uuid.uuid4())  # ユニークなIDを生成\n",
    "\n",
    "        try:\n",
    "            collections[category].add(\n",
    "                ids=[doc_id],\n",
    "                documents=[chunk],\n",
    "                metadatas=[{\"source\": file_path, \"category\": category, \"chunk_index\": idx}],\n",
    "                embeddings=[embedding]\n",
    "            )\n",
    "            print(f\"✅ チャンク {idx+1}/{len(text_chunks)} 登録完了: {file_path} → {category} (ID: {doc_id})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ChromaDB 登録エラー: {str(e)}\")\n",
    "\n",
    "# ✅ ChromaDB 内のデータを確認\n",
    "def check_chromadb_data():\n",
    "    \"\"\"ChromaDB にデータが正しく登録されているか確認\"\"\"\n",
    "    for category, collection in collections.items():\n",
    "        try:\n",
    "            data = collection.peek()\n",
    "            print(f\"📌 {category} コレクションのデータ:\")\n",
    "            print(data)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ コレクション {category} のデータ確認エラー: {str(e)}\")\n",
    "\n",
    "# ✅ クエリのリライト（LLMを利用）\n",
    "def rewrite_query(query):\n",
    "    \"\"\"LLM を使ってクエリを拡張\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    ユーザーのクエリをより具体的に拡張してください。\n",
    "    \n",
    "    クエリ: {query}\n",
    "    \n",
    "    出力例: 2025年2月の金融市場動向と米国株式市場の関係\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        if hasattr(response, \"text\") and response.text:\n",
    "            print(f\"🟢 クエリ拡張成功: {response.text}\")\n",
    "            return response.text.strip()\n",
    "        else:\n",
    "            print(f\"⚠️ クエリ拡張失敗（レスポンス不正）: {response}\")\n",
    "            return query\n",
    "    except Exception as e:\n",
    "        print(f\"❌ クエリ拡張エラー: {str(e)}\")\n",
    "        return query\n",
    "\n",
    "# ✅ ChromaDB に問い合わせ（類似度フィルタ適用）\n",
    "def retrieve_relevant_info(query: str, top_k=3, min_score=0.1):\n",
    "    \"\"\"ChromaDB から類似情報を取得（類似度閾値なし）\"\"\"\n",
    "    expanded_query = rewrite_query(query)  # クエリ拡張\n",
    "    print(f\"🟢 クエリ拡張後: {expanded_query}\")\n",
    "\n",
    "    query_embedding = get_gemini_embedding(expanded_query)  # ✅ クエリをベクトル化\n",
    "    if query_embedding is None:\n",
    "        print(\"❌ クエリ埋め込みの取得に失敗しました\")\n",
    "        return \"🔍 クエリの埋め込みに失敗しました。\"\n",
    "\n",
    "    # ✅ クエリ埋め込みの次元確認\n",
    "    print(f\"✅ クエリの埋め込みベクトルの次元: {len(query_embedding)}\")\n",
    "\n",
    "    # ✅ ChromaDB に格納されているデータの埋め込み次元確認\n",
    "    peek_data = collections[\"daily\"].peek()\n",
    "    if \"embeddings\" in peek_data and len(peek_data[\"embeddings\"]) > 0:\n",
    "        print(f\"✅ 格納済みデータの埋め込みベクトルの次元: {len(peek_data['embeddings'][0])}\")\n",
    "    \n",
    "    try:\n",
    "        results = collections[\"daily\"].query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=top_k,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ クエリ実行エラー: {str(e)}\")\n",
    "        return \"🔍 クエリの実行に失敗しました。\"\n",
    "\n",
    "    if not results.get(\"documents\"):\n",
    "        return \"🔍 関連情報なし\"\n",
    "\n",
    "    retrieved_docs = []\n",
    "    for i in range(len(results[\"documents\"][0])):\n",
    "        score = results[\"distances\"][0][i]\n",
    "        if score < min_score:\n",
    "            continue  # スコアが低すぎる場合は無視\n",
    "\n",
    "        retrieved_docs.append(f\"🔹 類似情報 {i+1}: {results['documents'][0][i][:200]}...\")\n",
    "        retrieved_docs.append(f\"📝 メタデータ: {results['metadatas'][0][i]}\")\n",
    "        retrieved_docs.append(f\"🔢 類似度スコア: {score:.4f}\")\n",
    "        retrieved_docs.append(\"-\" * 50)\n",
    "\n",
    "    return \"\\n\".join(retrieved_docs) if retrieved_docs else \"🔍 適切な情報が見つかりませんでした。\"\n",
    "    for i in range(len(results[\"documents\"][0])):\n",
    "        retrieved_docs.append(f\"🔹 類似情報 {i+1}: {results['documents'][0][i][:200]}...\")\n",
    "        retrieved_docs.append(f\"📝 メタデータ: {results['metadatas'][0][i]}\")\n",
    "        retrieved_docs.append(f\"🔢 類似度スコア: {results['distances'][0][i]:.4f}\")\n",
    "        retrieved_docs.append(\"-\" * 50)\n",
    "\n",
    "    return \"\\n\".join(retrieved_docs) if retrieved_docs else \"🔍 適切な情報が見つかりませんでした。\"\n",
    "\n",
    "# ✅ LLM に検索結果を要約させる\n",
    "def summarize_retrieved_info(query: str, top_k=3):\n",
    "    \"\"\"RAG 検索結果を LLM で要約\"\"\"\n",
    "    retrieved_docs = retrieve_relevant_info(query, top_k)\n",
    "    \n",
    "    if \"🔍 適切な情報が見つかりませんでした。\" in retrieved_docs:\n",
    "        print(\"❌ 要約不可: 適切な検索結果がありません。\")\n",
    "        return \"🔍 要約できる情報が見つかりませんでした。\"\n",
    "\n",
    "    summary_prompt = f\"\"\"\n",
    "    あなたは金融市場の専門家です。\n",
    "    以下の情報を要約し、最近の金融市場の動向について詳しく解説してください。\n",
    "\n",
    "    ### 🔍 検索結果:\n",
    "    {retrieved_docs}\n",
    "\n",
    "    ---\n",
    "    \n",
    "    要約:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = gemini_model.generate_content(summary_prompt)\n",
    "        \n",
    "        if hasattr(response, \"text\") and response.text:\n",
    "            print(f\"📝 要約成功: {response.text.strip()}\")\n",
    "            return response.text.strip()\n",
    "        else:\n",
    "            print(f\"⚠️ 要約失敗（レスポンス不正）: {response}\")\n",
    "            return \"🔍 要約生成に失敗しました。\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 要約エラー: {str(e)}\")\n",
    "        return \"🔍 要約の生成に失敗しました。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867dd1d-affe-4b9f-96dd-5dcc20c9af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ テスト用PDFの登録\n",
    "INPUT_DIR = \"input/data-rag/\"\n",
    "pdf_files = {\n",
    "    INPUT_DIR + \"daily250221.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"daily250220.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"daily250219.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"daily250218.pdf\": \"daily\",\n",
    "    INPUT_DIR + \"250217_weekly.pdf\": \"weekly\",\n",
    "    INPUT_DIR + \"250210_weekly.pdf\": \"weekly\",\n",
    "    INPUT_DIR + \"250203_weekly.pdf\": \"weekly\",\n",
    "    INPUT_DIR + \"monthly_2502.pdf\": \"monthly\",\n",
    "}\n",
    "\n",
    "for file, category in pdf_files.items():\n",
    "    process_pdf(file, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1c6bce04-2500-437d-a5a5-781e78b7c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 daily コレクションのデータ:\n",
      "{'ids': ['e11eb683-06b3-43ce-9335-00265a6bbcce', 'ea1fbf0e-5e74-4c63-a394-6f71c359307d', 'effac6bc-a97e-4301-9ecc-0a2b146d4028', '2286e071-66d7-4d95-b235-ca62335673e9', '1f42c9a3-4219-48f5-9105-18bc126f0458', '012c83bf-b44d-4b2f-bf4a-bb6508760dbd', 'ca9cdedd-bb77-4e46-b286-04acceb57b52', '87e8a556-bb36-4ed7-bc13-fdb0efab89c5', '21ab6f28-6791-49d8-86d3-a6b67f8861d2', '843de30d-9ae5-458f-93ab-7e6d06ec27c0'], 'embeddings': array([[ 0.0447529 ,  0.06725755, -0.035169  , ..., -0.04462361,\n",
      "         0.05318881, -0.05041842],\n",
      "       [ 0.04112265,  0.03121432,  0.024434  , ..., -0.05765102,\n",
      "         0.0257796 , -0.04316479],\n",
      "       [ 0.02719103,  0.04258162, -0.04399061, ..., -0.06919848,\n",
      "         0.05181579, -0.04099518],\n",
      "       ...,\n",
      "       [ 0.00447275,  0.04896156, -0.05324043, ...,  0.00534078,\n",
      "         0.07214562, -0.00303894],\n",
      "       [-0.02352262,  0.03660674, -0.00744899, ...,  0.00512246,\n",
      "         0.07658856, -0.03041998],\n",
      "       [ 0.03006796,  0.07615107, -0.03256498, ..., -0.08491544,\n",
      "         0.03507243, -0.02122584]]), 'metadatas': [{'category': 'daily', 'chunk_index': 0, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 1, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 2, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 3, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 4, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 5, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 6, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 7, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 8, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 9, 'source': 'input/data-rag/daily250221.pdf'}], 'documents': ['D 情報提供資料\\n投資環境デイリー\\n2025年2月21日号\\n経済調査室\\ns\\nu 米国株下落、米個人消費の先行き不安を意識\\nc\\no\\nF\\n主要金融市場の動き 主要国株式の動き\\n株式 （単位：ポイント） 2月20日 2月19日 前日差 48,000 （日経平均株価:円、NYダウ:米ドル） （DAX®:ポイント） 25,000\\n日本 日経平均株価 （円） 38,678.04 39,164.61 -486.57 46,000 NYダウ（左軸） 24,000\\n- CME日経平均先物 （円） 38,555.00 38,985.00 -430.00 44,000 日経平均株価（左軸） 23,000', 'TOPIX（東証株価指数） 2,734.60 2,767.25 -32.65 42,000 22,000\\n参考） 東証REIT指数 1,686.61 1,686.64 -0.03 40,000 21,000\\n米国 NYダウ （米ドル） 44,176.65 44,627.59 -450.94 38,000 20,000\\nS&P500 6,117.52 6,144.15 -26.63 36,000 19,000\\n- S&P500配当貴族指数 4,713.51 4,700.20 13.31 34,000 DAX®（右軸） 18,000', 'ナスダック総合指数 19,962.36 20,056.25 -93.89 32,000 17,000\\nドイツ DAX®指数 22,314.65 22,433.63 -118.98 30,000 16,000\\n2024/2/23 2024/6/22 2024/10/20 2025/2/17 (年/月/日)\\n英国 FTSE100指数 8,662.97 8,712.53 -49.56\\n注）直近値は2025年2月20日\\n豪州 S&P/ASX200指数 8,322.82 8,419.19 -96.37', '豪州 S&P/ASX200指数 8,322.82 8,419.19 -96.37\\n中国 上海総合指数 3,350.78 3,351.54 -0.76 出所）Bloombergより当社経済調査室作成\\n香港 ハンセン指数 22,576.98 22,944.24 -367.26\\nインド S&P BSE SENSEX指数 75,735.96 75,939.18 -203.22\\nﾌﾞﾗｼﾞﾙ ボベスパ指数 127,600.58 127,308.80 291.78 ◆マーケットの動き：\\n先進国 MSCI WORLD 3,893.65 3,906.82 -13.17', '先進国 MSCI WORLD 3,893.65 3,906.82 -13.17\\n新興国 MSCI EM 1,132.45 1,136.87 -4.42\\n●日本株軟調。円高進行や日銀追加利上げ観測を嫌気。\\n商品 （単位：米ドル） 2月20日 2月19日 前日差\\n原油 WTI先物 （期近物） 72.57 72.25 0.32\\n本日公表される日本の1月消費者物価上振れリスクへの\\n金 COMEX先物 （期近物） 2,940.00 2,919.40 20.60 警戒感も。植田日銀総裁は石破首相と昨年10月以来2回\\n目の会談。国内の長期金利上昇は話題に上らずと言及。', '目の会談。国内の長期金利上昇は話題に上らずと言及。\\n10年国債利回り （単位：%） 2月20日 2月19日 前日差\\n日本 1.440 1.435 0.005 ●中国人民銀行は銀行貸出の指標となる最優遇貸出金\\n米国 4.506 4.534 -0.028 利の1年物を3.10%、5年物を3.60%に予想通り据え置き。\\nドイツ 2.534 2.557 -0.023 ●豪ドル底堅い。豪州1月雇用統計で失業率は4.1%に上\\nオーストラリア 4.525 4.525 0.001\\n昇も、就業者数は前月差+4.4万人と予想を大幅に上回る。', '昇も、就業者数は前月差+4.4万人と予想を大幅に上回る。\\n為替（対円） （単位：円） 2月20日 2月19日 前日比% ●ユーロは対米ドルで上昇。ユーロ圏2月消費者信頼感\\n米ドル 149.64 151.47 ▲1.21\\n指数は▲13.6と2カ月連続上昇。家計心理の改善を示唆。\\nユーロ 157.16 157.88 ▲0.46\\n●米国株軟調。米小売大手ウォルマートの決算発表で\\n英ポンド 189.57 190.65 ▲0.57\\n業績見通しが予想を下回り消費の先行き不安を意識。\\nカナダドル 105.58 106.42 ▲0.79', 'カナダドル 105.58 106.42 ▲0.79\\nオーストラリア（豪）ドル 95.78 96.10 ▲0.34 セントルイス連銀総裁は米経済のスタグフレーション\\nNZ（ニュージーランド）ドル 86.24 86.38 ▲0.17 （景気低迷と物価上昇の同時進行）リスクを指摘。米\\nシンガポールドル 112.22 112.79 ▲0.51 株安に伴い円相場は昨年12月以来の1米ドル149円台に。\\n中国人民元 20.661 20.833 ▲0.83\\nインドルピー 1.7267 1.7449 ▲1.04\\n◆本日の注目点：\\nインドネシアルピア（100ルピア） 0.9161 0.9279 ▲1.27', '◆本日の注目点：\\nインドネシアルピア（100ルピア） 0.9161 0.9279 ▲1.27\\nメキシコペソ 7.365 7.408 ▲0.59 米欧の製造業回復の動きは一時的か、持続的か\\nブラジルレアル 26.239 26.477 ▲0.90\\nトルコリラ 4.108 4.170 ▲1.48 米欧先進国で2月購買担当者景気指数（PMI、業況改善･\\nロシアルーブル 1.6872 1.6916 ▲0.26 悪化の境目は50）速報を公表。注目は製造業。米国が2', '注）CME: シカゴ･マーカンタイル取引所。CME日経平均先物は円建て契約で、単位: ポイント。 カ月連続の50超え（予想51.4）、ユーロ圏（同47.0）と\\nMSCI WORLD、MSCI EMは米ドルベース。\\nWTI（West Texas Intermediate）原油先物：ニューヨーク・マーカンタイル取引所（NYMEX）で\\n取引される米国の代表的な原油先物。 ドイツ（同45.5）が2カ月連続上昇となれば、製造業回\\nCOMEX金先物：CMEグループを構成するニューヨーク商品取引所で取引される代表的な金先物。'], 'data': None, 'uris': None, 'included': ['embeddings', 'documents', 'metadatas']}\n",
      "📌 weekly コレクションのデータ:\n",
      "{'ids': ['a5fecf59-f632-4818-a18a-48bca71ddcbe', 'fed87ab3-5aa3-42cc-8fb8-cb279bc42934', '75afc390-f188-4831-9e22-0a8f3162d14d', '2f598f33-2221-4c3a-931a-80f85c737b7c', '9b0097d5-0e10-4820-859a-3c836f9a40ca', '1756469d-f103-4ad3-ba55-655180a53d34', '15b41823-a0e9-484e-8e7b-9d0eed2d049c', '3d0cb880-9b07-42b9-9c14-ac12c41562a7', '298ece3d-e05b-4ce6-92c7-86d325b40945', '11640437-00df-4e1e-8ac0-352b4848d91e'], 'embeddings': array([[ 0.00290218,  0.05129908, -0.02875092, ..., -0.03092461,\n",
      "         0.06300305, -0.0859343 ],\n",
      "       [ 0.03169704,  0.04932573, -0.0645259 , ..., -0.02780441,\n",
      "         0.05342558, -0.04848745],\n",
      "       [ 0.02389368,  0.04266896, -0.0582892 , ..., -0.03960128,\n",
      "         0.01246695, -0.06525505],\n",
      "       ...,\n",
      "       [ 0.03855731,  0.02318168, -0.01699027, ..., -0.05047184,\n",
      "         0.05411306, -0.03565209],\n",
      "       [ 0.04174113,  0.02368618, -0.01639282, ..., -0.04558758,\n",
      "         0.05526394, -0.02798935],\n",
      "       [ 0.01431531,  0.03394596, -0.00560277, ..., -0.07560077,\n",
      "         0.05106326, -0.02355062]]), 'metadatas': [{'category': 'weekly', 'chunk_index': 0, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 1, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 2, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 3, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 4, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 5, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 6, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 7, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 8, 'source': 'input/data-rag/250217_weekly.pdf'}, {'category': 'weekly', 'chunk_index': 9, 'source': 'input/data-rag/250217_weekly.pdf'}], 'documents': ['情報提供資料\\nW\\n投資環境ウィークリー\\n2025年2月17日\\n経済調査室\\ns\\nu 米利下げという追い風弱まる株式市場、悪材料に過敏となりやすい環境か\\nc\\no\\nF\\n● 景気･雇用は底堅く、インフレは下げ渋り ● 今週の主要経済指標と政治スケジュール\\n世界 総合PMI（購買担当者景気指数） ★は特に注目度の高いイベント\\n項目別指数 2/17 月\\n65\\nトランプ （日） 10-12月期 実質GDP（1次速報、前期比年率）\\n生産価格\\n第1次政権 7-9月期：+1.7%、10-12月期：+2.8%\\n60\\n生産増 2/18 火\\n生産\\n雇用増 ★ （米） 2月ニューヨーク連銀製造業景気指数', '60\\n生産増 2/18 火\\n生産\\n雇用増 ★ （米） 2月ニューヨーク連銀製造業景気指数\\n55 価格上昇 1月：▲12.6、2月：（予）▲2.0\\n↑ （独） 2月ZEW景況感指数\\n期待 1月：+10.3、2月：（予）17.5\\n50 現況 1月：▲90.4、2月：（予）▲89.0\\n★ （豪） 金融政策決定会合（結果公表）\\nキャッシュレート：4.35%→（予）4.10%\\n45 ↓\\n雇用 （他） イスラエルとヒズボラの停戦期限\\n生産減\\n雇用減\\n40 2/19 水\\n価格低下\\n★ （米） FOMC議事録（1月28-29日分）\\n35 2/20 木\\n（年）', '価格低下\\n★ （米） FOMC議事録（1月28-29日分）\\n35 2/20 木\\n（年）\\n2017 2019 2021 2023 2025 ★ （米） 2月フィラデルフィア連銀製造業景気指数\\n1月：+44.3、2月：（予）+20.0\\n注）生産増･減、雇用増･減、価格上昇･低下の境目は50。\\n（米） 新規失業保険申請件数（週間）\\n直近値は2025年1月。\\n2月8日終了週：21.3万件\\n出所）S&Pグローバルより当社経済調査室作成 2月15日終了週：（予）21.5万件\\n2/21 金\\n■ 米国関税策と利下げ期待後退に耐える株式\\n★ （日） 1月消費者物価（全国、前年比）', '■ 米国関税策と利下げ期待後退に耐える株式\\n★ （日） 1月消費者物価（全国、前年比）\\n先週の株式市場は堅調を保ちました。トランプ米大統\\n総合 12月：+3.6%、1月：（予）+3.9%\\n除く生鮮 12月：+3.0%、1月：（予）+3.1%\\n領が新たな関税措置を連日発表、パウエル米連邦準備理\\n除く生鮮･エネルギー\\n事会（FRB）議長の利下げ慎重姿勢や1月の米物価指標上 12月：+2.4%、1月：（予）+2.5%\\n振れなどを受け、米金利上昇が進み株価が上値を重くす （日） 2月製造業PMI（速報）\\nる場面もありましたが、全体で冷静さを保ちました。\\n1月：48.7、2月：（予）NA', 'る場面もありましたが、全体で冷静さを保ちました。\\n1月：48.7、2月：（予）NA\\n★ （米） 2月製造業PMI（速報）\\n1月：51.2、2月：（予）51.2\\n■ 製造業回復の動きは持続的か？一時的か？\\n（米） 2月サービス業PMI（速報）\\n1月：52.9、2月：（予）53.0\\n下支えとなるのが、主要国景気の底堅さです。1月は米\\n★ （欧） 2月製造業PMI（速報）\\n欧製造業に回復の兆しもうかがえました。ただし、これ\\n1月：46.6、2月：（予）47.0\\nが持続的か、または今年のトランプ関税発動を見越した ★ （独） 2月製造業PMI（速報）', 'が持続的か、または今年のトランプ関税発動を見越した ★ （独） 2月製造業PMI（速報）\\n駆け込み需要による一時的な動きかは、今週から順次公 1月：45.0、2月：（予）45.5\\n表される2月景気指標から判断することになりそうです。\\n2/23 日\\n★ （独） 総選挙\\n■ 地政学問題やインフレ再燃リスクに注意\\n米国中心に主要国の雇用環境は安定、消費主導の景気\\n回復基調が早晩崩れる公算は低いとみます（上図）。た\\n注）（日）は日本、（米）は米国、（欧）はユーロ圏、（英）は英国、\\nだし米利下げ期待が弱まるなか、株式市場では貿易摩擦\\n（独）はドイツ、（仏）はフランス、（伊）はイタリア、', '（独）はドイツ、（仏）はフランス、（伊）はイタリア、\\nや地政学リスクなど、景気減速･インフレ再燃につながり （豪）はオーストラリア、（中）は中国、（伯）はブラジルを指します。\\n日程および内容は変更される可能性があります。\\nうる材料が警戒されやすい点は要注意です。（瀧澤）\\n出所）各種情報、Bloombergより当社経済調査室作成\\n巻末の「本資料に関してご留意頂きたい事項」\\nおよび「本資料中で使用している指数について」を必ずご覧ください。\\n1\\nWW\\n投資環境ウィークリー 2025年2月17日号\\n金融市場の動向\\n● 主要金融市場の動き（直近1週間） ● 株式市場の動き', '金融市場の動向\\n● 主要金融市場の動き（直近1週間） ● 株式市場の動き\\n※騰落幅および騰落率は直近値の1週間前比 （日経平均株価：円、NYダウ：米ドル、DAX®：ポイント）\\n50,000\\n株式 （単位：ポイント） 2月14日 騰落幅 騰落率%\\n45,000 44,546\\n日本 日経平均株価 （円） 39,149.43 362.41 0.93\\nTOPIX 2,759.21 21.98 0.80 40,000 NYダウ 39,149\\n米国 NYダウ （米ドル） 44,546.08 242.68 0.55 35,000\\nS&P500 6,114.63 88.64 1.47\\n30,000', 'S&P500 6,114.63 88.64 1.47\\n30,000\\nﾅｽﾀﾞｯｸ総合指数 20,026.77 503.37 2.58\\n25,000\\n欧州 ｽﾄｯｸｽ・ﾖｰﾛｯﾊﾟ600 552.41 9.66 1.78\\n日経平均株価 22,513\\nドイツ DAX®指数 22,513.42 726.42 3.33 20,000\\n英国 FTSE100指数 8,732.46 31.93 0.37 15,000\\n中国 上海総合指数 3,346.72 43.06 1.30 DAX®\\n10,000\\n先進国 MSCI WORLD 3,898.87 66.05 1.72\\n5,000', '10,000\\n先進国 MSCI WORLD 3,898.87 66.05 1.72\\n5,000\\n新興国 MSCI EM 1,125.23 16.75 1.51\\n（年）\\n2020/2/25 2022/2/25 2024/2/25\\nリート （単位：ポイント） 2月14日 騰落幅 騰落率%\\n先進国 S&P先進国REIT指数 264.78 1.42 0.54\\n● 長期金利（10年国債利回り）の動き\\n日本 東証REIT指数 1,679.94 4.32 0.26\\n（%）\\n10年国債利回り （単位：%） 2月14日 騰落幅 6.0\\n日本 1.350 0.050\\n5.0 米国'], 'data': None, 'uris': None, 'included': ['embeddings', 'documents', 'metadatas']}\n",
      "📌 monthly コレクションのデータ:\n",
      "{'ids': ['458cf3e2-7cbe-4905-ae89-a2badc89d8e4', '2f1e1c22-4aed-4131-9f8b-c7e94926a2c3', '7f3465f6-da87-4d3c-8918-584603f5f413', 'cde06776-72da-4d5f-879c-1e9f671b4583', '900a6650-02e0-4d32-9c9c-12bd634c57b7', '46aac565-5f0c-4204-b4f4-54dab9ea181c', '5e1bbf9c-fda0-4719-b3c3-90f5a0780143', '72cec70e-eb3e-4062-b921-df636bb6cc87', '8ee16b37-29d6-495a-83c8-31edd9b74f76', 'e357d4b7-34c5-4944-ae17-4f67ab98ee82'], 'embeddings': array([[ 0.04277892,  0.04283186, -0.02663939, ..., -0.03683328,\n",
      "         0.00816165, -0.02861796],\n",
      "       [ 0.02732016,  0.02311269, -0.02337596, ..., -0.0579721 ,\n",
      "         0.05378267, -0.04625915],\n",
      "       [-0.00904239,  0.03920135, -0.01745874, ..., -0.00742256,\n",
      "         0.02609558, -0.05704659],\n",
      "       ...,\n",
      "       [ 0.02135536,  0.04921634, -0.04886198, ..., -0.0285314 ,\n",
      "         0.06381325, -0.07109845],\n",
      "       [ 0.04926648,  0.06384547, -0.03919236, ..., -0.02023856,\n",
      "         0.05333945, -0.03556473],\n",
      "       [ 0.01354394,  0.01854209, -0.04459021, ...,  0.0124868 ,\n",
      "         0.05185949, -0.03897501]]), 'metadatas': [{'category': 'monthly', 'chunk_index': 0, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 1, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 2, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 3, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 4, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 5, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 6, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 7, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 8, 'source': 'input/data-rag/monthly_2502.pdf'}, {'category': 'monthly', 'chunk_index': 9, 'source': 'input/data-rag/monthly_2502.pdf'}], 'documents': ['I\\nNVESTMENT\\nS M\\nTRATEGY ONTHLY\\n＜投資戦略マンスリー＞\\n2025年2月\\n01 世界経済･金融市場見通し 27 市場データ一覧\\n03 各国経済見通し 28 主要金融資産のパフォーマンス\\n17 市場見通し 29 主要な政治･経済日程\\nINVESTMENT STRATEGY MONTHLY\\n① 世 界 経 済 ･ 金 融 市 場 見 通 し\\n2025年2月\\n【図1】2025年1月の主要国景気はまだら模様、\\n世界経済\\nユーロ圏復調も、要の米国･中国が減速\\n米欧中 総合PMI（購買担当者景気指数）\\n1月の主要国景気は米中と日欧に温度差も\\n70', '米欧中 総合PMI（購買担当者景気指数）\\n1月の主要国景気は米中と日欧に温度差も\\n70\\n1月の主要国景気は好悪材料が混在しました。1月総合\\n購買担当者景気指数（PMI、改善･悪化の境目50）を見る 65\\nと、日本が3カ月連続で上昇、ユーロ圏が3カ月ぶりに50 ↑業況改善\\n台を回復するなど安定感を高めた一方、米国は4カ月ぶり 60\\n米国\\nに低下（以上S&Pグローバル）、中国（国家統計局）も\\n52.4\\n大幅に低下しました（図1）。米中両国では昨年の景気を 55\\n下支えしてきたサービス業の減速が目立った印象です。\\n50\\n世界の景気軟着陸への確信はまだ得られず\\nﾕｰﾛ圏\\n45', '50\\n世界の景気軟着陸への確信はまだ得られず\\nﾕｰﾛ圏\\n45\\n米国では雇用改善が続くなか、足腰の強い消費を背景 50.2\\nにサービス業回復は続くとみます。他方、製造業は、上 中国\\n↓業況悪化\\n40\\n記PMIで米国が7カ月ぶりに50台を回復、ユーロ圏も最悪 50.1\\n期脱却の兆しを見せるも、中国は4カ月ぶりの50割れとま\\n35\\nちまちです。米トランプ政権動向（2月から対カナダ･メ （年）\\n2017 2019 2021 2023 2025\\nキシコの関税引き上げ予告）への不透明感もあり、全体\\n注）PMIは50が業況改善･悪化の境目。', 'キシコの関税引き上げ予告）への不透明感もあり、全体\\n注）PMIは50が業況改善･悪化の境目。\\nで楽観論の強まりにくい環境が続くとみます。（瀧澤） 米国･ユーロ圏がS&Pグローバル、中国が中国国家統計局の公表値。\\n直近値は2025年1月（米国･ユーロ圏は速報ベース）。\\n出所）S&Pグローバル、中国国家統計局より当社経済調査室作成\\n【図2】米トランプ政権誕生後の国際金融市場で、\\n金融市場\\n米国一人勝ちの構図が是正されるかも注目\\n世界株式（国･地域別）と米ドル名目実効レート\\n1月はトランプリスク後退に安堵する場面も\\n（2023年末=100）\\n170 115', '1月はトランプリスク後退に安堵する場面も\\n（2023年末=100）\\n170 115\\n1月の金融市場は月半ば以降、米インフレ懸念後退に 米ドル名目実効レート（右軸）\\n160\\n伴う年内利下げ期待の回復、米トランプ新政権の政策に\\n↑米ドル高 110\\n対する過度な警戒感（関税引き上げや不法移民強制送還 150 ↓米ドル安\\nによるインフレ加速懸念など）の後退などもあり、リス\\n105\\n140\\nク選好色を強めました。株式市場は米国以外の国で増勢\\nを強めるなど、昨秋の米利下げ開始後に際立った米国一 130\\n100\\n人勝ちの構図に変化の兆しも見られた印象です（図2）。\\n120\\n米国株（左軸）\\n95', '100\\n人勝ちの構図に変化の兆しも見られた印象です（図2）。\\n120\\n米国株（左軸）\\n95\\nトランプ2.0にどう対峙するかここからが本番 110\\n100\\n米トランプ大統領の一般教書や予算教書が公表される 90\\n2月以降の金融市場は、その政策の実現性を巡り神経戦が 90\\n展開されそうです。パナマ運河返還やグリーンランド領 85\\n世界株\\n80\\n有権を巡る問題同様、同大統領の突飛な発言で揺さぶら （除く米国、左軸）\\nれる場面もあるでしょう。また低金利志向とされる同大 70 80\\n（年）\\n統領が、連邦公開市場委員会（FOMC）の4会合ぶりの利 2021 2022 2023 2024 2025', '注）米ドル名目実効レートはFRB算出のBroad指数。米国株はMSCI USA、\\n下げ見送り後にどう反応するかも要注意です。（瀧澤）\\n世界株（除く米国）はMSCI ACWI ex USA（ともに米ドルベース）。\\n指数化は当社経済調査室。直近値は2025年1月24日。\\n出所）MSCI、FRB、LSEGより当社経済調査室作成\\n巻末の「本資料に関してご留意頂きたい事項」\\nおよび「本資料中で使用している指数について」を必ずご覧ください。\\n1\\nINVESTMENT STRATEGY MONTHLY\\n① 世 界 経 済 ･ 金 融 市 場 見 通 し\\n2025年2月\\n● 実質GDP（前年比）見通し', '① 世 界 経 済 ･ 金 融 市 場 見 通 し\\n2025年2月\\n● 実質GDP（前年比）見通し\\n2022年 2023年 2024年 2025年 2022年 2023年 2024年 2025年\\n日本 0.9 1.5 ▲ 0.2 1.4 中国 3.1 5.4 5.0 4.2\\n米国 2.5 2.9 2.8 2.0 インド 7.0 8.2 6.3 6.4\\nユーロ圏 3.5 0.4 0.7 0.8 ブラジル 3.0 3.2 3.0 2.0\\nオーストラリア 4.1 2.0 1.0 2.1 メキシコ 3.7 3.3 1.6 1.4', 'オーストラリア 4.1 2.0 1.0 2.1 メキシコ 3.7 3.3 1.6 1.4\\n注）2022-2023年は実績、2024-2025年が当社経済調査室推計･見通し。\\n● 金融市場（6カ月後）見通し\\n株 式\\n直近値 6ヵ月後の見通し 直近値 6ヵ月後の見通し\\n（単位：ポイント） （単位：ポイント）\\n日経平均株価（円） 39,415 38,000-44,000 NYダウ（米ドル） 44,714 41,700-47,700\\n日本 米国\\nTOPIX 2,776 2,650-3,050 S&P500 6,039 5,750-6,550\\nｽﾄｯｸｽ・ﾖｰﾛｯﾊﾟ600 534 490-570', 'ｽﾄｯｸｽ・ﾖｰﾛｯﾊﾟ600 534 490-570\\n欧州\\nドイツDAX®指数 21,638 19,600-22,400\\n債 券\\n（ 1 0 年 国 債 利 回 り ）\\n直近値 6ヵ月後の見通し 直近値 6ヵ月後の見通し\\n（単位：%） （単位：%）\\n日本 1.190 1.0-1.6 欧州（ドイツ） 2.583 1.7-2.7\\n米国 4.530 3.7-4.9 オーストラリア 4.370 3.7-4.7\\n為 替 （ 対 円 ）\\n直近値 6ヵ月後の見通し 直近値 6ヵ月後の見通し\\n（単位：円） （単位：円）\\n米ドル 155.22 141-159 インドルピー 1.7919 1.70-1.90'], 'data': None, 'uris': None, 'included': ['embeddings', 'documents', 'metadatas']}\n",
      "🟢 クエリ拡張成功: いくつかの拡張例を提案します。クエリ「マーケットの動きとして日本動向を教えて」をより具体的に拡張するには、以下の要素を考慮する必要があります。\n",
      "\n",
      "**1. 対象となる市場の指定:**\n",
      "\n",
      "* **特定の市場:**  「日本の株式市場の動向を教えてください。特に、2023年10月からの動きと、今後数ヶ月の予想について教えてください。」\n",
      "* **複数の市場:** 「日本の株式市場、債券市場、不動産市場の最近の動向と、それぞれの市場間の相互作用について教えてください。」\n",
      "* **セクター別:** 「日本のテクノロジーセクターの市場動向、特に半導体関連企業の株価について教えてください。」\n",
      "\n",
      "\n",
      "**2. 期間の指定:**\n",
      "\n",
      "* **特定の期間:** 「2023年第3四半期の日本の経済指標と、それらが市場に与えた影響について教えてください。」\n",
      "* **相対的な期間:** 「最近の日本の市場動向と、過去1年間の動きとの比較を教えてください。」\n",
      "\n",
      "\n",
      "**3. 影響要因の指定:**\n",
      "\n",
      "* **経済指標:** 「日本のGDP成長率、消費者物価指数、失業率などの経済指標が、最近の市場動向にどう影響しているか教えてください。」\n",
      "* **政策:** 「日銀の金融政策が、日本の市場にどのような影響を与えているか教えてください。」\n",
      "* **世界情勢:** 「最近のウクライナ情勢や原油価格の高騰が、日本の市場に与える影響について教えてください。」\n",
      "* **特定のイベント:** 「最近の円安傾向の原因と、それが日本の市場に与える影響について教えてください。」\n",
      "\n",
      "\n",
      "**4. 必要な情報の指定:**\n",
      "\n",
      "* **分析結果:** 「日本の市場動向に関する専門家の分析や予測を教えてください。」\n",
      "* **データ:** 「日本の主要経済指標のデータとチャートを提供してください。」\n",
      "* **ニュース:** 「日本の市場に影響を与えた最近のニュースを教えてください。」\n",
      "\n",
      "\n",
      "**出力例 (拡張されたクエリに基づいて):**\n",
      "\n",
      "* 「2023年10月から現在までの日本の日経平均株価の動き、および円ドルの為替レートの変動、そしてそれらに影響を与えた主要な要因を分析してください。」\n",
      "* 「日本の不動産市場の動向、特に東京圏のマンション価格の推移と、今後数年間の市場予測を教えてください。また、金利上昇の影響についても分析してください。」\n",
      "* 「日銀の金融緩和政策が、日本の株式市場と債券市場に及ぼした影響について、2022年から2024年までのデータに基づいて分析してください。特に、長期金利への影響に焦点を当ててください。」\n",
      "\n",
      "\n",
      "このように、元のクエリをより具体的な情報を含めることで、より正確で有益な回答を得ることができます。\n",
      "\n",
      "🟢 クエリ拡張後: いくつかの拡張例を提案します。クエリ「マーケットの動きとして日本動向を教えて」をより具体的に拡張するには、以下の要素を考慮する必要があります。\n",
      "\n",
      "**1. 対象となる市場の指定:**\n",
      "\n",
      "* **特定の市場:**  「日本の株式市場の動向を教えてください。特に、2023年10月からの動きと、今後数ヶ月の予想について教えてください。」\n",
      "* **複数の市場:** 「日本の株式市場、債券市場、不動産市場の最近の動向と、それぞれの市場間の相互作用について教えてください。」\n",
      "* **セクター別:** 「日本のテクノロジーセクターの市場動向、特に半導体関連企業の株価について教えてください。」\n",
      "\n",
      "\n",
      "**2. 期間の指定:**\n",
      "\n",
      "* **特定の期間:** 「2023年第3四半期の日本の経済指標と、それらが市場に与えた影響について教えてください。」\n",
      "* **相対的な期間:** 「最近の日本の市場動向と、過去1年間の動きとの比較を教えてください。」\n",
      "\n",
      "\n",
      "**3. 影響要因の指定:**\n",
      "\n",
      "* **経済指標:** 「日本のGDP成長率、消費者物価指数、失業率などの経済指標が、最近の市場動向にどう影響しているか教えてください。」\n",
      "* **政策:** 「日銀の金融政策が、日本の市場にどのような影響を与えているか教えてください。」\n",
      "* **世界情勢:** 「最近のウクライナ情勢や原油価格の高騰が、日本の市場に与える影響について教えてください。」\n",
      "* **特定のイベント:** 「最近の円安傾向の原因と、それが日本の市場に与える影響について教えてください。」\n",
      "\n",
      "\n",
      "**4. 必要な情報の指定:**\n",
      "\n",
      "* **分析結果:** 「日本の市場動向に関する専門家の分析や予測を教えてください。」\n",
      "* **データ:** 「日本の主要経済指標のデータとチャートを提供してください。」\n",
      "* **ニュース:** 「日本の市場に影響を与えた最近のニュースを教えてください。」\n",
      "\n",
      "\n",
      "**出力例 (拡張されたクエリに基づいて):**\n",
      "\n",
      "* 「2023年10月から現在までの日本の日経平均株価の動き、および円ドルの為替レートの変動、そしてそれらに影響を与えた主要な要因を分析してください。」\n",
      "* 「日本の不動産市場の動向、特に東京圏のマンション価格の推移と、今後数年間の市場予測を教えてください。また、金利上昇の影響についても分析してください。」\n",
      "* 「日銀の金融緩和政策が、日本の株式市場と債券市場に及ぼした影響について、2022年から2024年までのデータに基づいて分析してください。特に、長期金利への影響に焦点を当ててください。」\n",
      "\n",
      "\n",
      "このように、元のクエリをより具体的な情報を含めることで、より正確で有益な回答を得ることができます。\n",
      "✅ クエリの埋め込みベクトルの次元: 768\n",
      "✅ 格納済みデータの埋め込みベクトルの次元: 768\n",
      "📝 要約成功: 提供されたデータは、2024年2月頃の金融市場の動向を示唆する断片的な情報です。主に、ドイツ10年国債利回り、日本10年国債利回り、米ドル円、ユーロドルの為替レート、そして米国のGDP成長率に関連する情報が含まれています。\n",
      "\n",
      "**最近の金融市場動向の解説:**\n",
      "\n",
      "データからは、以下の傾向が読み取れます。\n",
      "\n",
      "* **国債利回りの動向:** ドイツ10年国債利回りと日本10年国債利回りの推移を示すグラフ（正確な数値は欠損しているため傾向のみを述べます）は、期間中に変動していることを示しています。具体的な数値がないため、上昇傾向か下降傾向かは断定できませんが、市場の動向を反映して変化していると考えられます。  この変動は、市場の金利に対する期待や経済情勢の変化を反映している可能性が高いです。\n",
      "\n",
      "* **為替レートの動向:** 米ドル円とユーロドルの為替レートも同様に、期間中に変動しています。こちらも具体的な数値がないため、上昇・下降傾向は断定できませんが、市場参加者のセンチメントや経済指標、各国の中央銀行の政策などに影響を受けていると考えられます。\n",
      "\n",
      "* **米国経済の好調:** 類似情報3からは、12月期の米国の実質GDPが市場予想を上回ったことが金利上昇圧力につながったと記されています。これは、米国経済の堅調さを示し、それに伴い金利が上昇する可能性を示唆しています。  高いGDP成長率は、インフレ懸念を高め、中央銀行による利上げ圧力につながる可能性があります。\n",
      "\n",
      "**全体像と考察:**\n",
      "\n",
      "これらの情報は断片的なため、明確な結論を出すことは困難です。しかし、米国経済の好調とそれに伴う金利上昇圧力、そしてドイツと日本の国債利回りの変動、為替レートの変動は、相互に関連している可能性があります。例えば、米国経済の好調はドル高を招き、ユーロや円安につながる可能性があります。また、金利上昇圧力は、国債利回りの上昇に繋がり、投資家の行動にも影響を与えます。\n",
      "\n",
      "より詳細な分析を行うためには、以下の情報が必要です。\n",
      "\n",
      "* グラフの正確な数値と単位\n",
      "* 各日付における具体的な数値\n",
      "* 他の経済指標（インフレ率、失業率など）\n",
      "* 各国の中央銀行の政策動向\n",
      "\n",
      "これらの情報があれば、より正確で包括的な金融市場の動向分析が可能になります。  現状の断片的な情報からは、市場が動的であり、様々な要因によって影響を受けていることが示唆されるのみです。\n",
      "\n",
      "=== 🔥 LLM による要約結果 ===\n",
      "提供されたデータは、2024年2月頃の金融市場の動向を示唆する断片的な情報です。主に、ドイツ10年国債利回り、日本10年国債利回り、米ドル円、ユーロドルの為替レート、そして米国のGDP成長率に関連する情報が含まれています。\n",
      "\n",
      "**最近の金融市場動向の解説:**\n",
      "\n",
      "データからは、以下の傾向が読み取れます。\n",
      "\n",
      "* **国債利回りの動向:** ドイツ10年国債利回りと日本10年国債利回りの推移を示すグラフ（正確な数値は欠損しているため傾向のみを述べます）は、期間中に変動していることを示しています。具体的な数値がないため、上昇傾向か下降傾向かは断定できませんが、市場の動向を反映して変化していると考えられます。  この変動は、市場の金利に対する期待や経済情勢の変化を反映している可能性が高いです。\n",
      "\n",
      "* **為替レートの動向:** 米ドル円とユーロドルの為替レートも同様に、期間中に変動しています。こちらも具体的な数値がないため、上昇・下降傾向は断定できませんが、市場参加者のセンチメントや経済指標、各国の中央銀行の政策などに影響を受けていると考えられます。\n",
      "\n",
      "* **米国経済の好調:** 類似情報3からは、12月期の米国の実質GDPが市場予想を上回ったことが金利上昇圧力につながったと記されています。これは、米国経済の堅調さを示し、それに伴い金利が上昇する可能性を示唆しています。  高いGDP成長率は、インフレ懸念を高め、中央銀行による利上げ圧力につながる可能性があります。\n",
      "\n",
      "**全体像と考察:**\n",
      "\n",
      "これらの情報は断片的なため、明確な結論を出すことは困難です。しかし、米国経済の好調とそれに伴う金利上昇圧力、そしてドイツと日本の国債利回りの変動、為替レートの変動は、相互に関連している可能性があります。例えば、米国経済の好調はドル高を招き、ユーロや円安につながる可能性があります。また、金利上昇圧力は、国債利回りの上昇に繋がり、投資家の行動にも影響を与えます。\n",
      "\n",
      "より詳細な分析を行うためには、以下の情報が必要です。\n",
      "\n",
      "* グラフの正確な数値と単位\n",
      "* 各日付における具体的な数値\n",
      "* 他の経済指標（インフレ率、失業率など）\n",
      "* 各国の中央銀行の政策動向\n",
      "\n",
      "これらの情報があれば、より正確で包括的な金融市場の動向分析が可能になります。  現状の断片的な情報からは、市場が動的であり、様々な要因によって影響を受けていることが示唆されるのみです。\n"
     ]
    }
   ],
   "source": [
    "# ✅ 検証用コード\n",
    "if __name__ == \"__main__\":\n",
    "    check_chromadb_data()  # ChromaDB にデータが登録されているか確認\n",
    "\n",
    "    # クエリの実行と LLM での要約\n",
    "    query_text = \"マーケットの動きとして日本動向を教えて\"\n",
    "    summary_info = summarize_retrieved_info(query_text, top_k=3)\n",
    "\n",
    "    print(\"\\n=== 🔥 LLM による要約結果 ===\")\n",
    "    print(summary_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "416c0398-d607-4778-bd5d-89c86995f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#原因調査"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bbeefbe5-c173-47aa-8af4-a6c6c3527cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 クエリと最初のデータの類似度: 0.47075930205331534\n"
     ]
    }
   ],
   "source": [
    "query_text = \"最近の金融市場動向\"\n",
    "query_embedding = get_gemini_embedding(query_text)\n",
    "\n",
    "peek_data = collections[\"daily\"].peek()\n",
    "stored_embedding = peek_data[\"embeddings\"][0]  # 最初のデータ\n",
    "\n",
    "similarity = sum(q * s for q, s in zip(query_embedding, stored_embedding))  # 内積計算\n",
    "print(f\"🔍 クエリと最初のデータの類似度: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dc4de4f5-a248-4d3b-b9f9-94677a21f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 格納済みデータの埋め込みベクトルの次元: 768\n"
     ]
    }
   ],
   "source": [
    "peek_data = collections[\"daily\"].peek()\n",
    "print(f\"✅ 格納済みデータの埋め込みベクトルの次元: {len(peek_data['embeddings'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1b67b733-3ad1-4491-b271-21a55a147c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 クエリ拡張成功: いくつかの拡張例を挙げます。元のクエリ「最近の金融市場動向」は非常に広いため、より具体的な情報を引き出すには、時間軸、市場の種類、影響要因など、様々な要素を考慮する必要があります。\n",
      "\n",
      "**時間軸を絞り込んだ例:**\n",
      "\n",
      "* **2024年第4四半期のグローバル金融市場動向とインフレ率の関係**\n",
      "* **過去3ヶ月の主要中央銀行の金融政策と債券市場への影響**\n",
      "* **今年度の日本の金融市場動向と円安の関連性**\n",
      "\n",
      "**市場の種類を指定した例:**\n",
      "\n",
      "* **最近のテクノロジー株市場の動向とAI関連企業の株価変動**\n",
      "* **最近の原油価格の動向とエネルギーセクターへの影響**\n",
      "* **最近の暗号通貨市場の動向と規制の影響**\n",
      "\n",
      "**影響要因を指定した例:**\n",
      "\n",
      "* **最近の地政学的リスクが金融市場に与える影響と今後の展望**\n",
      "* **最近のサプライチェーン問題が金融市場動向に及ぼす影響**\n",
      "* **最近の金利上昇が不動産市場に与える影響**\n",
      "\n",
      "**より複合的な例:**\n",
      "\n",
      "* **2024年後半における米国と中国の金融市場の相互作用と貿易摩擦の影響**\n",
      "* **最近のインフレ抑制策と主要国の金融政策による株式市場への影響分析**\n",
      "* **持続可能な投資への関心の高まりが最近の金融市場動向に与えている影響**\n",
      "\n",
      "\n",
      "このように、元のクエリを拡張するには、**「いつ」「どこで」「何が」「なぜ」**という点を具体的に記述することが重要です。  より具体的なクエリを作成することで、より正確で有益な情報を得ることができます。\n",
      "\n",
      "🟢 クエリ拡張後: いくつかの拡張例を挙げます。元のクエリ「最近の金融市場動向」は非常に広いため、より具体的な情報を引き出すには、時間軸、市場の種類、影響要因など、様々な要素を考慮する必要があります。\n",
      "\n",
      "**時間軸を絞り込んだ例:**\n",
      "\n",
      "* **2024年第4四半期のグローバル金融市場動向とインフレ率の関係**\n",
      "* **過去3ヶ月の主要中央銀行の金融政策と債券市場への影響**\n",
      "* **今年度の日本の金融市場動向と円安の関連性**\n",
      "\n",
      "**市場の種類を指定した例:**\n",
      "\n",
      "* **最近のテクノロジー株市場の動向とAI関連企業の株価変動**\n",
      "* **最近の原油価格の動向とエネルギーセクターへの影響**\n",
      "* **最近の暗号通貨市場の動向と規制の影響**\n",
      "\n",
      "**影響要因を指定した例:**\n",
      "\n",
      "* **最近の地政学的リスクが金融市場に与える影響と今後の展望**\n",
      "* **最近のサプライチェーン問題が金融市場動向に及ぼす影響**\n",
      "* **最近の金利上昇が不動産市場に与える影響**\n",
      "\n",
      "**より複合的な例:**\n",
      "\n",
      "* **2024年後半における米国と中国の金融市場の相互作用と貿易摩擦の影響**\n",
      "* **最近のインフレ抑制策と主要国の金融政策による株式市場への影響分析**\n",
      "* **持続可能な投資への関心の高まりが最近の金融市場動向に与えている影響**\n",
      "\n",
      "\n",
      "このように、元のクエリを拡張するには、**「いつ」「どこで」「何が」「なぜ」**という点を具体的に記述することが重要です。  より具体的なクエリを作成することで、より正確で有益な情報を得ることができます。\n"
     ]
    }
   ],
   "source": [
    "query_text = \"最近の金融市場動向\"\n",
    "expanded_query = rewrite_query(query_text)\n",
    "print(f\"🟢 クエリ拡張後: {expanded_query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7245a37c-3856-485c-9fca-77c4a0429884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 クエリ拡張成功: いくつかの具体的に拡張したクエリ例を挙げます。それぞれ異なる側面に焦点を当てています。\n",
      "\n",
      "* **マクロ経済要因に焦点を当てた例:**  `2025年2月の金融市場動向：インフレ率、金利、原油価格の影響分析`\n",
      "\n",
      "* **特定の市場セクターに焦点を当てた例:** `2025年2月の金融市場動向：テクノロジー株市場の動向と今後の展望`  または `2025年2月の金融市場動向：新興市場国債の動向とリスク要因`\n",
      "\n",
      "* **地域に焦点を当てた例:** `2025年2月の金融市場動向：欧州株式市場の動向と米国市場との相関関係` または `2025年2月の金融市場動向：アジア太平洋地域の金融市場の動向と地政学的リスクの影響`\n",
      "\n",
      "* **特定のイベントへの影響に焦点を当てた例:** `2025年2月の金融市場動向：最新の利上げ発表が株式市場に与えた影響分析` または  `2025年2月の金融市場動向：主要中央銀行の金融政策変更が為替レートに与えた影響`\n",
      "\n",
      "* **予測モデルを含めた例:** `2025年2月の金融市場動向：時系列分析を用いた今後の市場予測とリスク評価`\n",
      "\n",
      "\n",
      "これらの例は、元のクエリ「最近の金融市場動向」をより具体的な情報要求に拡張しています。  どの拡張が最適かは、ユーザーの具体的な興味や分析の目的によって異なります。\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'いくつかの具体的に拡張したクエリ例を挙げます。それぞれ異なる側面に焦点を当てています。\\n\\n* **マクロ経済要因に焦点を当てた例:**  `2025年2月の金融市場動向：インフレ率、金利、原油価格の影響分析`\\n\\n* **特定の市場セクターに焦点を当てた例:** `2025年2月の金融市場動向：テクノロジー株市場の動向と今後の展望`  または `2025年2月の金融市場動向：新興市場国債の動向とリスク要因`\\n\\n* **地域に焦点を当てた例:** `2025年2月の金融市場動向：欧州株式市場の動向と米国市場との相関関係` または `2025年2月の金融市場動向：アジア太平洋地域の金融市場の動向と地政学的リスクの影響`\\n\\n* **特定のイベントへの影響に焦点を当てた例:** `2025年2月の金融市場動向：最新の利上げ発表が株式市場に与えた影響分析` または  `2025年2月の金融市場動向：主要中央銀行の金融政策変更が為替レートに与えた影響`\\n\\n* **予測モデルを含めた例:** `2025年2月の金融市場動向：時系列分析を用いた今後の市場予測とリスク評価`\\n\\n\\nこれらの例は、元のクエリ「最近の金融市場動向」をより具体的な情報要求に拡張しています。  どの拡張が最適かは、ユーザーの具体的な興味や分析の目的によって異なります。'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text = \"最近の金融市場動向\"\n",
    "rewrite_query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "19b42404-902b-4abb-87f6-b72770de0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = get_gemini_embedding(query_text)  # 拡張せずそのまま"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3761c83b-cdb8-4d89-ac2f-77ccb8baa4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 テストクエリ検索結果: {'ids': [['d68bad8a-19a2-4b27-b498-34fc5065f4b0', '44118f1a-a0ec-41e7-9ea9-30c0c57854cb', '445cff83-d8b0-47d4-ac62-98d5b8b6562f', '46687a48-7f53-4c33-ae65-217d5cd941ca', '012c83bf-b44d-4b2f-bf4a-bb6508760dbd']], 'distances': [[0.6512641310691833, 0.7175018787384033, 0.7827810645103455, 0.8001096844673157, 0.8119246363639832]], 'embeddings': None, 'metadatas': [[{'category': 'daily', 'chunk_index': 6, 'source': 'input/data-rag/daily250220.pdf'}, {'category': 'daily', 'chunk_index': 11, 'source': 'input/data-rag/daily250219.pdf'}, {'category': 'daily', 'chunk_index': 7, 'source': 'input/data-rag/daily250220.pdf'}, {'category': 'daily', 'chunk_index': 14, 'source': 'input/data-rag/daily250221.pdf'}, {'category': 'daily', 'chunk_index': 5, 'source': 'input/data-rag/daily250221.pdf'}]], 'documents': [['為替（対円） （単位：円） 2月19日 2月18日 前日比% 懸念から、量的引き締めの減速や一時停止の検討の必\\n米ドル 151.47 152.06 ▲0.39 要性が言及されたことが好感され、相場を下支え。\\nユーロ 157.88 158.84 ▲0.60 ●欧州株は大幅下落。トランプ米大統領が、4月にも輸\\n英ポンド 190.65 191.81 ▲0.60 入される自動車に25%程度、半導体･医薬品にも同程度\\nカナダドル 106.42 107.12 ▲0.66\\nの関税を課す方針を示し、市場不安が再度高まった。\\nオーストラリア（豪）ドル 96.10 96.60 ▲0.52', '(%) （円/米ドル、ユーロ） （米ドル/ユーロ）\\n5.0 180 1.50\\n4.5 175 ユーロ円（左軸） 1.45\\n4.0 170 1.40\\n3.5 米国10年国債利回り 165 1.35\\n3.0 160 1.30\\n2.5 155 1.25\\n2.0 150 1.20\\nドイツ10年国債利回り\\n1.5 145 米ドル円（左軸） 1.15\\n1.0 140 1.10\\n0.5 日本10年国債利回り 135 ユーロドル（右軸） 1.05\\n0.0 130 1.00', 'オーストラリア（豪）ドル 96.10 96.60 ▲0.52\\n●ニュージーランド(NZ)準備銀行(中銀)は、景気下支え\\nNZ（ニュージーランド）ドル 86.38 86.72 ▲0.39\\nシンガポールドル 112.79 113.28 ▲0.43\\nのため、0.5%ptの利下げを決定し、政策金利を3.75%と\\n中国人民元 20.833 20.890 ▲0.27 した。最新の利下げ到達点見通しは、昨年11月見通し\\nインドルピー 1.7449 1.7439 0.06 から引き下げ。ハト派姿勢が強まり、NZドルは下落。\\nインドネシアルピア（100ルピア） 0.9279 0.9342 ▲0.67', '■本資料の内容は作成時点のものであり、将来予告なく変更されることがあります。\\n■本資料は信頼できると判断した情報等に基づき作成しておりますが、その正確性・完全性等を保証するものではありません。\\n■各ページのグラフ・データ等は、過去の実績・状況または作成時点での見通し・分析であり、将来の市場環境の変動や運用状況・成果を示\\n唆・保証するものではありません。また、税金・手数料等を考慮しておりません。\\n■本資料に示す意見等は、特に断りのない限り本資料作成日現在の三菱UFJアセットマネジメント戦略運用部経済調査室の見解です。また、三菱', '目の会談。国内の長期金利上昇は話題に上らずと言及。\\n10年国債利回り （単位：%） 2月20日 2月19日 前日差\\n日本 1.440 1.435 0.005 ●中国人民銀行は銀行貸出の指標となる最優遇貸出金\\n米国 4.506 4.534 -0.028 利の1年物を3.10%、5年物を3.60%に予想通り据え置き。\\nドイツ 2.534 2.557 -0.023 ●豪ドル底堅い。豪州1月雇用統計で失業率は4.1%に上\\nオーストラリア 4.525 4.525 0.001\\n昇も、就業者数は前月差+4.4万人と予想を大幅に上回る。']], 'uris': None, 'data': None, 'included': ['distances', 'documents', 'metadatas']}\n"
     ]
    }
   ],
   "source": [
    "test_query_embedding = get_gemini_embedding(\"金融市場\")\n",
    "test_results = collections[\"daily\"].query(\n",
    "    query_embeddings=[test_query_embedding],\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")\n",
    "print(f\"🔍 テストクエリ検索結果: {test_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1ec5b-cef7-4e1a-a707-9220a556ae44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
